# Flink SQL 窗口函数

**Learning Point**: 3.1 from knowledge_and_skills_needed_v2.md
**Prerequisites**: 1.3 (Table API/SQL), 1.6 (Windows), SQL window functions knowledge
**Version**: Flink 2.2.0

---

## 工程化定义

**TUMBLE Window Function**: 用于创建滚动（非重叠）时间窗口的 Flink SQL 函数。将事件分组到固定大小、非重叠的时间间隔中。

**TUMBLE_START**: 提取滚动窗口的开始时间戳。

**TUMBLE_END**: 提取滚动窗口的结束时间戳。

**Window Aggregation**: 在窗口数据上应用聚合函数（COUNT、SUM、AVG 等）。

**GROUP BY Window**: 同时按 key 和 window 分组，以便按每个 key 每个窗口进行聚合。

---

## 通俗解释

将 TUMBLE window functions 想象成每小时报告：

- **TUMBLE** = 小时桶：将事件分组到 1 小时的桶中
- **TUMBLE_START** = 桶开始时间："这个桶从 14:00 开始"
- **TUMBLE_END** = 桶结束时间："这个桶在 15:00 结束"
- **Aggregation** = 汇总：统计事件数，对每个桶中的值求和

**为什么需要**：MarketLag Job 1 按小时聚合 RSS 事件——同一小时内的所有事件被分组并聚合。

---

## 类比理解

如果您了解 **SQL window functions**（您了解），Flink 的 TUMBLE 类似，但用于流处理：
- SQL `OVER (PARTITION BY ... ORDER BY ... ROWS BETWEEN ...)` = Flink TUMBLE（但基于时间，而非基于行）
- SQL 在分区上聚合 = Flink 在窗口上聚合

关键区别：Flink 窗口基于时间且连续（无界），SQL 窗口基于行且有界。

---

## 与已学内容的关系

- **1.6 Windows**: TUMBLE 创建滚动窗口（在第 1.6 节中介绍）
- **1.3 Table API/SQL**: TUMBLE 是一个 Flink SQL 函数
- **1.5 Watermarks**: 窗口使用 watermarks 来触发（第 1.5 节）
- **SQL Aggregations**: 您已经从 SQL 中了解 COUNT、SUM、AVG

---

## 伪代码（基于源码）

Based on Flink 2.2.0 source code:

```sql
-- TUMBLE function (simplified parsing)
TUMBLE(time_col, INTERVAL '1' HOUR)
-- Parses to: TumblingWindowAssigner with 1-hour size
-- Groups events into [00:00, 01:00), [01:00, 02:00), etc.

-- TUMBLE_START (simplified)
TUMBLE_START(time_col, INTERVAL '1' HOUR)
-- Returns: Window start timestamp for current window

-- TUMBLE_END (simplified)
TUMBLE_END(time_col, INTERVAL '1' HOUR)
-- Returns: Window end timestamp for current window
```

---

## 源码参考

**Local Path**: `generation_pipeline/step0_context/source_codes/flink/flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/functions/SqlLikeWindowFunction.java`

**GitHub URL**: https://github.com/apache/flink/blob/release-2.2/flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/functions/SqlLikeWindowFunction.java

---

## TUMBLE 窗口函数语法

### Basic TUMBLE Syntax

```sql
SELECT
    key,
    TUMBLE_START(time_col, INTERVAL '1' HOUR) as window_start,
    TUMBLE_END(time_col, INTERVAL '1' HOUR) as window_end,
    COUNT(*) as count
FROM table
GROUP BY key, TUMBLE(time_col, INTERVAL '1' HOUR);
```

**关键点**：
- GROUP BY 中的 `TUMBLE(time_col, INTERVAL 'N' UNIT)` 创建窗口
- `TUMBLE_START` 和 `TUMBLE_END` 提取窗口边界
- 必须同时按 key 和 TUMBLE window 分组

### MarketLag Job 1 Example

```sql
SELECT
    market_slug,
    TUMBLE_START(published_at, INTERVAL '1' HOUR) as window_start,
    TUMBLE_END(published_at, INTERVAL '1' HOUR) as window_end,
    COUNT(*) as mention_count,
    SUM(keyword_score) as keyword_score,
    AVG(article_score * source_weight) as source_weighted_signal
FROM rss_events
GROUP BY market_slug, TUMBLE(published_at, INTERVAL '1' HOUR);
```

**This is the exact pattern used in MarketLag Job 1**.

---

## 窗口聚合：COUNT/SUM/AVG 等

### COUNT Over Windows

```sql
SELECT
    key,
    TUMBLE_START(time_col, INTERVAL '1' HOUR) as window_start,
    COUNT(*) as event_count
FROM table
GROUP BY key, TUMBLE(time_col, INTERVAL '1' HOUR);
```

统计每个 key 每个窗口的事件数。

### SUM Over Windows

```sql
SELECT
    key,
    TUMBLE_START(time_col, INTERVAL '1' HOUR) as window_start,
    SUM(value) as total_value
FROM table
GROUP BY key, TUMBLE(time_col, INTERVAL '1' HOUR);
```

对每个 key 每个窗口的值求和。

### AVG Over Windows

```sql
SELECT
    key,
    TUMBLE_START(time_col, INTERVAL '1' HOUR) as window_start,
    AVG(value) as avg_value
FROM table
GROUP BY key, TUMBLE(time_col, INTERVAL '1' HOUR);
```

计算每个 key 每个窗口的平均值。

**MarketLag Job 1**: Uses COUNT (mention_count), SUM (keyword_score), and AVG (source_weighted_signal).

---

## 窗口开始与结束时间提取

### TUMBLE_START

Extracts the start timestamp of the window:

```sql
TUMBLE_START(published_at, INTERVAL '1' HOUR)
-- For event at 14:30:00, returns: 14:00:00
-- For event at 15:15:00, returns: 15:00:00
```

### TUMBLE_END

Extracts the end timestamp of the window:

```sql
TUMBLE_END(published_at, INTERVAL '1' HOUR)
-- For event at 14:30:00, returns: 15:00:00
-- For event at 15:15:00, returns: 16:00:00
```

**Note**: Window end is exclusive (not inclusive). Window [14:00, 15:00) includes 14:00:00 but not 15:00:00.

---

## 按窗口与 key 分组

### GROUP BY Syntax

```sql
GROUP BY key, TUMBLE(time_col, INTERVAL '1' HOUR)
```

**重要**：必须同时按以下两项分组：
1. **Key**（例如，market_slug）：按 key 分组事件
2. **TUMBLE window**：按时间窗口分组事件

### 为什么两者都需要

- **Key**：确保聚合是按 key 进行的（例如，按市场）
- **Window**：确保聚合是按时间段进行的（例如，按小时）

**MarketLag Job 1**: Groups by `market_slug` (key) and `TUMBLE(published_at, INTERVAL '1' HOUR)` (window).

---

## 最小可用代码

```java
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;

public class WindowFunctionsDemo {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);

        // Create source table
        tableEnv.executeSql(
            "CREATE TABLE events (" +
            "  key STRING," +
            "  value DOUBLE," +
            "  event_time TIMESTAMP(3)," +
            "  WATERMARK FOR event_time AS event_time - INTERVAL '5' MINUTE" +
            ") WITH (" +
            "  'connector' = 'kafka'," +
            "  'topic' = 'events'," +
            "  'properties.bootstrap.servers' = 'localhost:9092'," +
            "  'format' = 'json'" +
            ")"
        );

        // Window aggregation
        tableEnv.executeSql(
            "CREATE TABLE windowed_results AS " +
            "SELECT " +
            "  key," +
            "  TUMBLE_START(event_time, INTERVAL '1' HOUR) as window_start," +
            "  TUMBLE_END(event_time, INTERVAL '1' HOUR) as window_end," +
            "  COUNT(*) as count," +
            "  SUM(value) as total," +
            "  AVG(value) as avg_value " +
            "FROM events " +
            "GROUP BY key, TUMBLE(event_time, INTERVAL '1' HOUR)"
        );

        env.execute("Window Functions Demo");
    }
}
```

---

## 常见错误

1. **GROUP BY 中缺少 TUMBLE**：
   - ❌ `GROUP BY key`（没有窗口分组）
   - ✅ `GROUP BY key, TUMBLE(time_col, INTERVAL '1' HOUR)`

2. **错误的时间列**：
   - ❌ 使用 processing time 而不是 event time
   - ✅ 使用带有 WATERMARK 声明的 event time 列

3. **缺少 WATERMARK**：
   - ❌ 没有 watermarks 时窗口永远不会触发
   - ✅ 始终在 CREATE TABLE 中声明 WATERMARK（第 1.5 节）

4. **错误的窗口大小语法**：
   - ❌ `INTERVAL 1 HOUR`（缺少引号）
   - ✅ `INTERVAL '1' HOUR`（需要引号）

5. **不理解窗口边界**：
   - ❌ 期望包含结束时间
   - ✅ 窗口结束时间是排他的：[start, end)

---

## 触发点：什么时候想到这个概念

在以下情况下考虑 Flink SQL window functions：
- **编写 Job 1**：MarketLag Job 1 使用 TUMBLE 进行每小时 RSS 聚合
- **基于时间的聚合**：需要按时间段聚合事件
- **窗口边界**：理解 TUMBLE_START 和 TUMBLE_END
- **GROUP BY windows**：必须同时按 key 和 TUMBLE window 分组
- **Watermark 集成**：当 watermark 超过窗口结束时触发窗口

**在 MarketLag 项目中**：Job 1 使用 TUMBLE window functions 按小时聚合 RSS 事件。按 market_slug 和 TUMBLE(published_at, INTERVAL '1' HOUR) 分组，计算每个市场每小时的 mention_count、keyword_score 和 source_weighted_signal。

---

## 小结

Flink SQL TUMBLE window functions 创建滚动（非重叠）时间窗口。TUMBLE_START 和 TUMBLE_END 提取窗口边界。窗口聚合（COUNT、SUM、AVG）按每个 key 每个窗口应用。必须同时按 key 和 TUMBLE window 分组。MarketLag Job 1 使用 TUMBLE 进行每小时 RSS 信号聚合。理解 window functions 对于流式 SQL 中基于时间的聚合至关重要。

