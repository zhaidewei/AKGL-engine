# Flink 时间概念和时区处理

**Learning Point**: 1.4 from knowledge_and_skills_needed_v2.md
**Prerequisites**: 1.3 (Table API/SQL), 理解时间戳和时区（您已从数据工程中了解）
**Version**: Flink 2.2.0

---

## 工程化定义

**Processing Time**: Flink 算子处理事件时的挂钟时间。由处理事件的机器的系统时钟确定。

**Event Time**: 事件在现实世界中实际发生的时间戳，从事件数据本身提取。独立于处理时间。

**Ingestion Time**: 混合方法 - 在 Flink source 算子接收事件时分配的时间戳，在任何处理之前。

**UTC Standardization**: 将所有时间戳转换为协调世界时（UTC）以避免时区歧义。对于处理来自多个时区的数据的分布式系统至关重要。

**Event Time Alignment**: 确保事件时间戳对齐到特定边界（例如，小时边界），以便在分布式处理中实现一致的窗口化。

---

## 通俗解释

将 Flink 中的时间想象成包裹配送系统：

- **Processing Time** = 配送卡车扫描包裹的时间（Flink 处理时）
- **Event Time** = 包裹实际发货的时间（事件在现实世界中发生的时间）
- **Ingestion Time** = 包裹到达分拣设施的时间（Flink 接收时）

**为什么 Event Time 重要**: 如果包裹昨天发货但今天处理，您希望将其与昨天的包裹分组，而不是今天的。Event time 确保即使在处理延迟时也能正确按时间顺序排序。

**UTC 标准化**: 就像为所有仓库使用单一时区 - 当包裹来自不同时区时避免混淆。每个人都使用 UTC，然后仅在显示时转换为本地时间。

---

## 类比理解

如果您了解 **Spark Structured Streaming**（您了解），Flink 的时间概念类似：
- Spark 的 processing time = Flink processing time
- Spark 的 event time = Flink event time
- Spark 的 watermark = Flink watermark（在第 1.5 节中介绍）

关键区别：Flink 的事件时间处理比 Spark 的微批处理方法更成熟且延迟更低。

---

## 与已学内容的关系

- **1.3 Table API/SQL**: 时间属性在 CREATE TABLE 语句中声明
- **1.5 Watermarks**: Event time 需要 watermark 来处理延迟数据
- **1.6 Windows**: 窗口使用 event time 将事件分配到正确的时间窗口
- **Timezone Handling**: 您已从数据工程经验中了解时区处理 - Flink 应用相同的原则

---

## 伪代码（基于源码）

基于 Flink 2.2.0 源代码：

```java
// 时间提取（简化版）
class TimestampExtractor {
    long extractEventTime(Record record) {
        // 从记录字段提取时间戳
        return record.getField("event_time");
    }

    long getProcessingTime() {
        // 系统挂钟时间
        return System.currentTimeMillis();
    }

    long getIngestionTime() {
        // 在 source 接收记录时分配
        return System.currentTimeMillis();  // 在摄入时刻
    }
}

// 时间对齐（简化版）
class TimeAligner {
    long alignToHour(long timestamp) {
        // 对齐到 UTC 小时边界
        return (timestamp / 3600000) * 3600000;  // 向下取整到小时
    }
}
```

---

## 源码参考

**Local Path**: `generation_pipeline/step0_context/source_codes/flink/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/AssignerWithPeriodicWatermarks.java`

**GitHub URL**: https://github.com/apache/flink/blob/release-2.2/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/AssignerWithPeriodicWatermarks.java

**关键类**:
- `TimestampAssigner`: 为事件分配时间戳
- `WatermarkGenerator`: 生成 watermark（在第 1.5 节中介绍）

---

## 处理时间 vs 事件时间 vs 摄入时间

### Processing Time
- **Definition**: 算子处理事件时的系统时钟
- **Pros**: 简单，无需提取时间戳，低延迟
- **Cons**: 非确定性，结果随处理速度变化
- **使用场景**: 当精确的事件时间不重要时（例如，简单聚合）

```java
// 处理时间（自动）
DataStream<Event> stream = env.fromElements(...);
stream.map(...);  // 自动使用处理时间
```

### Event Time
- **Definition**: 来自事件数据本身的时间戳
- **Pros**: 确定性，正确处理乱序数据
- **Cons**: 需要提取时间戳，需要 watermark
- **使用场景**: 当时间顺序正确性重要时（MarketLag 项目使用此方式）

```java
// 事件时间（显式）
stream.assignTimestampsAndWatermarks(
    WatermarkStrategy
        .forBoundedOutOfOrderness(Duration.ofMinutes(5))
        .withTimestampAssigner((event, timestamp) -> event.getPublishedAt())
);
```

### Ingestion Time
- **Definition**: source 接收事件时分配的时间戳
- **Pros**: 自动，处理一些乱序
- **Cons**: 不如 event time 准确
- **使用场景**: 当 event time 不可用但需要比 processing time 更好时

```java
// 摄入时间
stream.assignTimestampsAndWatermarks(
    WatermarkStrategy.forMonotonousTimestamps()
        .withTimestampAssigner((event, timestamp) -> System.currentTimeMillis())
);
```

---

## UTC 标准化

### 为什么使用 UTC？

1. **Distributed Systems**: 不同时区的多台机器
2. **Data Sources**: RSS feed、Polymarket API 可能使用不同时区
3. **Consistency**: 时间戳的单一真实来源
4. **Window Alignment**: 窗口对齐到 UTC 边界（例如，UTC 小时 0、1、2...）

### 时区转换（本地 → UTC）

```java
// 示例：将本地时区转换为 UTC
String localTime = "2024-01-15 14:30:00 EST";  // 东部标准时间
ZonedDateTime local = ZonedDateTime.parse(localTime,
    DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss z"));
ZonedDateTime utc = local.withZoneSameInstant(ZoneId.of("UTC"));
long utcTimestamp = utc.toInstant().toEpochMilli();
```

### ISO 8601 格式

时间戳的标准格式：`2024-01-15T14:30:00Z` (Z = UTC)

```java
// 解析 ISO 8601
Instant instant = Instant.parse("2024-01-15T14:30:00Z");
long timestamp = instant.toEpochMilli();
```

---

## 从记录中提取事件时间

### 从 JSON 提取（MarketLag 项目模式）

```json
{
  "title": "Fed raises rates",
  "published_at": "2024-01-15T14:30:00Z",
  "source": "Reuters"
}
```

```java
// 从 JSON 字段提取事件时间
public class EventTimeExtractor implements TimestampAssigner<JsonNode> {
    @Override
    public long extractTimestamp(JsonNode element, long recordTimestamp) {
        String publishedAt = element.get("published_at").asText();
        return Instant.parse(publishedAt).toEpochMilli();
    }
}
```

### 在 Flink SQL 中

```sql
CREATE TABLE rss_events (
    title STRING,
    published_at TIMESTAMP(3),  -- Event time column
    source STRING,
    WATERMARK FOR published_at AS published_at - INTERVAL '5' MINUTE
) WITH (...);
```

---

## 事件时间对齐

### 小时对齐

事件必须对齐到 UTC 小时边界以实现一致的窗口化：

```java
// 将时间戳对齐到 UTC 小时边界
public long alignToHour(long timestamp) {
    // 转换为 UTC
    Instant instant = Instant.ofEpochMilli(timestamp);
    ZonedDateTime utc = instant.atZone(ZoneId.of("UTC"));

    // 向下取整到小时
    ZonedDateTime aligned = utc.withMinute(0).withSecond(0).withNano(0);
    return aligned.toInstant().toEpochMilli();
}
```

### 窗口对齐

在 MarketLag 项目中，窗口对齐到 UTC 小时：
- 窗口 1: 2024-01-15 00:00:00 UTC 到 01:00:00 UTC
- 窗口 2: 2024-01-15 01:00:00 UTC 到 02:00:00 UTC
- 等等

这确保了同一小时的所有事件被分组在一起，无论源时区如何。

---

## 最小可用代码

```java
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import java.time.Duration;
import java.time.Instant;
import java.time.ZoneId;
import java.time.ZonedDateTime;

public class TimeStampDemo {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment();

        // 创建带有 ISO 8601 时间戳的事件（支持 "Z" 和 "+08:00" 两种格式）
        @SuppressWarnings("deprecation")
        DataStream<Event> events = env.fromElements(
            new Event("event1", "login", "2024-01-01T20:00:00+08:00"),  // 北京时间 (UTC+8)
            new Event("event2", "click", "2024-01-01T12:01:00Z"),      // UTC
            new Event("event3", "logout", "2024-01-01T12:02:00Z")       // UTC
        );

        // 分配事件时间和 watermark
        DataStream<Event> withTimestamps = events.assignTimestampsAndWatermarks(
            WatermarkStrategy
                .<Event>forBoundedOutOfOrderness(Duration.ofMinutes(5))
                .withTimestampAssigner((event, timestamp) -> event.getTimestamp())
        );

        // 对齐到 UTC 小时边界（向下取整到小时的开始）
        DataStream<Event> aligned = withTimestamps.map(event -> {
            // 将时间戳转换为 UTC ZonedDateTime，然后对齐到小时边界
            ZonedDateTime zonedDateTime = Instant.ofEpochMilli(event.getTimestamp())
                .atZone(ZoneId.of("UTC"))
                .withMinute(0)
                .withSecond(0)
                .withNano(0);
            // 设置对齐后的时间戳（小时的开始）
            event.setAlignedTimestamp(zonedDateTime.toInstant().toEpochMilli());
            return event;
        });

        aligned.print();
        env.execute("Timestamp Demo");
    }
}

// Event 类定义
import java.time.Instant;
import java.time.ZonedDateTime;

class Event {
    public String user;
    public String action;
    public Long timestamp;
    public Long alignedTimestamp;  // 对齐到小时边界的时间戳

    public Event() {
        // Flink 所需的默认构造函数
    }

    public Event(String user, String action, String timestamp) {
        this.user = user;
        this.action = action;
        // 解析 ISO 8601 时间戳（支持 "Z" 和 "+08:00" 两种格式）
        try {
            // 先尝试 Instant.parse（用于 "Z" 格式）
            this.timestamp = Instant.parse(timestamp).toEpochMilli();
        } catch (Exception e) {
            // 如果失败，尝试 ZonedDateTime.parse（用于 "+08:00" 格式）
            this.timestamp = ZonedDateTime.parse(timestamp).toInstant().toEpochMilli();
        }
    }

    public Long getTimestamp() {
        return timestamp;
    }

    public void setAlignedTimestamp(Long alignedTimestamp) {
        this.alignedTimestamp = alignedTimestamp;
    }

    public Long getAlignedTimestamp() {
        return alignedTimestamp;
    }

    @Override
    public String toString() {
        return "Event{user='" + user + "', action='" + action + "', timestamp=" + timestamp +
               ", alignedTimestamp=" + alignedTimestamp + "}";
    }
}
```

---

## 时间戳分配策略

### 1. 从记录字段提取（最常见）
```java
.withTimestampAssigner((event, timestamp) -> event.getEventTime())
```

### 2. 从元数据提取（Kafka）
```java
.withTimestampAssigner(
    KafkaTimestampAssigner.create()  // 使用 Kafka 记录时间戳
)
```

### 3. 自定义提取
```java
.withTimestampAssigner((event, timestamp) -> {
    // 自定义逻辑来提取时间戳
    String timeStr = event.getField("time");
    return parseTimestamp(timeStr);
})
```

---

## 常见错误

1. **混合时间类型**:
   - ❌ 为事件时间窗口使用处理时间
   - ✅ 对于需要时间顺序正确性的窗口，始终使用事件时间

2. **时区混淆**:
   - ❌ 不转换为 UTC，混合时区
   - ✅ 在摄入时始终转换为 UTC，存储为 UTC，仅在显示时转换为本地时间

3. **时间戳精度**:
   - ❌ 在 SQL 中使用 TIMESTAMP 而不是 TIMESTAMP(3)
   - ✅ 使用 TIMESTAMP(3) 以获得毫秒精度（watermark 需要）

4. **不对齐到边界**:
   - ❌ 14:30 和 14:45 的事件在不同窗口中
   - ✅ 将所有时间戳对齐到小时边界以实现一致的窗口化

5. **ISO 8601 解析错误**:
   - ❌ 不处理时区指示符（Z、+05:00）
   - ✅ 始终使用时区感知解析，转换为 UTC

---

## 触发点：什么时候想到这个概念

在以下情况下考虑 Flink 时间概念：
- **设置事件时间处理**: MarketLag 项目的所有窗口都使用事件时间
- **处理时区数据**: RSS feed 和 Polymarket API 可能使用不同时区
- **配置 watermark**: 第 1.5 节要求首先设置事件时间
- **窗口对齐**: 第 1.6 节的窗口需要对齐的时间戳
- **调试窗口问题**: 未对齐的时间戳会导致事件进入错误的窗口

**在 MarketLag 项目中**: 所有时间戳都标准化为 UTC，对齐到小时边界。RSS 事件和 Polymarket 价格都使用 UTC 时间戳以实现一致的窗口化。

---

## 小结

Flink 支持三种时间概念：processing time（系统时钟）、event time（来自数据）和 ingestion time（在 source 处）。MarketLag 使用 event time 以确保时间顺序正确性。所有时间戳都标准化为 UTC 并对齐到小时边界以实现一致的窗口化。理解时间概念是 watermark（第 1.5 节）和窗口（第 1.6 节）的前提。

