# Flink 时间概念和时区处理

**Learning Point**: 1.4 from knowledge_and_skills_needed_v2.md
**Prerequisites**: 1.3 (Table API/SQL), 理解时间戳和时区（您已从数据工程中了解）
**Version**: Flink 2.2.0

---

## Definition (Engineering Language)

**Processing Time**: Flink 算子处理事件时的挂钟时间。由处理事件的机器的系统时钟确定。

**Event Time**: 事件在现实世界中实际发生的时间戳，从事件数据本身提取。独立于处理时间。

**Ingestion Time**: 混合方法 - 在 Flink source 算子接收事件时分配的时间戳，在任何处理之前。

**UTC Standardization**: 将所有时间戳转换为协调世界时（UTC）以避免时区歧义。对于处理来自多个时区的数据的分布式系统至关重要。

**Event Time Alignment**: 确保事件时间戳对齐到特定边界（例如，小时边界），以便在分布式处理中实现一致的窗口化。

---

## Plain Language Explanation

将 Flink 中的时间想象成包裹配送系统：

- **Processing Time** = 配送卡车扫描包裹的时间（Flink 处理时）
- **Event Time** = 包裹实际发货的时间（事件在现实世界中发生的时间）
- **Ingestion Time** = 包裹到达分拣设施的时间（Flink 接收时）

**为什么 Event Time 重要**: 如果包裹昨天发货但今天处理，您希望将其与昨天的包裹分组，而不是今天的。Event time 确保即使在处理延迟时也能正确按时间顺序排序。

**UTC Standardization**: 就像为所有仓库使用单一时区 - 当包裹来自不同时区时避免混淆。每个人都使用 UTC，然后仅在显示时转换为本地时间。

---

## Analogy

如果您了解 **Spark Structured Streaming**（您了解），Flink 的时间概念类似：
- Spark 的 processing time = Flink processing time
- Spark 的 event time = Flink event time
- Spark 的 watermark = Flink watermark（在第 1.5 节中介绍）

关键区别：Flink 的事件时间处理比 Spark 的微批处理方法更成熟且延迟更低。

---

## Relationship to Already Learned Topics

- **1.3 Table API/SQL**: 时间属性在 CREATE TABLE 语句中声明
- **1.5 Watermarks**: Event time 需要 watermark 来处理延迟数据
- **1.6 Windows**: 窗口使用 event time 将事件分配到正确的时间窗口
- **Timezone Handling**: 您已从数据工程经验中了解时区处理 - Flink 应用相同的原则

---

## Pseudocode (From Source Code)

Based on Flink 2.2.0 source code:

```java
// Time extraction (simplified)
class TimestampExtractor {
    long extractEventTime(Record record) {
        // Extract timestamp from record field
        return record.getField("event_time");
    }

    long getProcessingTime() {
        // System wall-clock time
        return System.currentTimeMillis();
    }

    long getIngestionTime() {
        // Assigned when source receives record
        return System.currentTimeMillis();  // At ingestion moment
    }
}

// Time alignment (simplified)
class TimeAligner {
    long alignToHour(long timestamp) {
        // Align to UTC hour boundary
        return (timestamp / 3600000) * 3600000;  // Round down to hour
    }
}
```

---

## Source Code References

**Local Path**: `generation_pipeline/step0_context/source_codes/flink/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/AssignerWithPeriodicWatermarks.java`

**GitHub URL**: https://github.com/apache/flink/blob/release-2.2/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/AssignerWithPeriodicWatermarks.java

**Key Classes**:
- `TimestampAssigner`: Assigns timestamps to events
- `WatermarkGenerator`: Generates watermarks (covered in section 1.5)

---

## Processing Time vs Event Time vs Ingestion Time

### Processing Time
- **Definition**: 算子处理事件时的系统时钟
- **Pros**: 简单，无需提取时间戳，低延迟
- **Cons**: 非确定性，结果随处理速度变化
- **Use Case**: 当精确的事件时间不重要时（例如，简单聚合）

```java
// Processing time (automatic)
DataStream<Event> stream = env.fromElements(...);
stream.map(...);  // Uses processing time automatically
```

### Event Time
- **Definition**: 来自事件数据本身的时间戳
- **Pros**: 确定性，正确处理乱序数据
- **Cons**: 需要提取时间戳，需要 watermark
- **Use Case**: 当时间顺序正确性重要时（MarketLag 项目使用此方式）

```java
// Event time (explicit)
stream.assignTimestampsAndWatermarks(
    WatermarkStrategy
        .forBoundedOutOfOrderness(Duration.ofMinutes(5))
        .withTimestampAssigner((event, timestamp) -> event.getPublishedAt())
);
```

### Ingestion Time
- **Definition**: source 接收事件时分配的时间戳
- **Pros**: 自动，处理一些乱序
- **Cons**: 不如 event time 准确
- **Use Case**: 当 event time 不可用但需要比 processing time 更好时

```java
// Ingestion time
stream.assignTimestampsAndWatermarks(
    WatermarkStrategy.forMonotonousTimestamps()
        .withTimestampAssigner((event, timestamp) -> System.currentTimeMillis())
);
```

---

## UTC Standardization

### Why UTC?

1. **Distributed Systems**: 不同时区的多台机器
2. **Data Sources**: RSS feed、Polymarket API 可能使用不同时区
3. **Consistency**: 时间戳的单一真实来源
4. **Window Alignment**: 窗口对齐到 UTC 边界（例如，UTC 小时 0、1、2...）

### Timezone Conversion (Local → UTC)

```java
// Example: Convert local timezone to UTC
String localTime = "2024-01-15 14:30:00 EST";  // Eastern Standard Time
ZonedDateTime local = ZonedDateTime.parse(localTime,
    DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss z"));
ZonedDateTime utc = local.withZoneSameInstant(ZoneId.of("UTC"));
long utcTimestamp = utc.toInstant().toEpochMilli();
```

### ISO 8601 Format

时间戳的标准格式：`2024-01-15T14:30:00Z` (Z = UTC)

```java
// Parse ISO 8601
Instant instant = Instant.parse("2024-01-15T14:30:00Z");
long timestamp = instant.toEpochMilli();
```

---

## Event Time Extraction from Records

### From JSON (MarketLag Project Pattern)

```json
{
  "title": "Fed raises rates",
  "published_at": "2024-01-15T14:30:00Z",
  "source": "Reuters"
}
```

```java
// Extract event time from JSON field
public class EventTimeExtractor implements TimestampAssigner<JsonNode> {
    @Override
    public long extractTimestamp(JsonNode element, long recordTimestamp) {
        String publishedAt = element.get("published_at").asText();
        return Instant.parse(publishedAt).toEpochMilli();
    }
}
```

### In Flink SQL

```sql
CREATE TABLE rss_events (
    title STRING,
    published_at TIMESTAMP(3),  -- Event time column
    source STRING,
    WATERMARK FOR published_at AS published_at - INTERVAL '5' MINUTE
) WITH (...);
```

---

## Event Time Alignment

### Hour Alignment

Events must align to UTC hour boundaries for consistent windowing:

```java
// Align timestamp to UTC hour boundary
public long alignToHour(long timestamp) {
    // Convert to UTC
    Instant instant = Instant.ofEpochMilli(timestamp);
    ZonedDateTime utc = instant.atZone(ZoneId.of("UTC"));

    // Round down to hour
    ZonedDateTime aligned = utc.withMinute(0).withSecond(0).withNano(0);
    return aligned.toInstant().toEpochMilli();
}
```

### Window Alignment

In MarketLag project, windows align to UTC hours:
- Window 1: 2024-01-15 00:00:00 UTC to 01:00:00 UTC
- Window 2: 2024-01-15 01:00:00 UTC to 02:00:00 UTC
- etc.

This ensures all events for the same hour are grouped together, regardless of source timezone.

---

## Minimum Viable Code

```java
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks;
import org.apache.flink.streaming.api.watermark.Watermark;
import java.time.Instant;
import java.time.ZoneId;
import java.time.ZonedDateTime;

public class TimeConceptsDemo {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // Create events with timestamps
        DataStream<Event> events = env.fromElements(
            new Event("event1", "2024-01-15T14:30:00Z"),
            new Event("event2", "2024-01-15T14:45:00Z"),
            new Event("event3", "2024-01-15T15:00:00Z")
        );

        // Assign event time and watermarks
        DataStream<Event> withTimestamps = events.assignTimestampsAndWatermarks(
            WatermarkStrategy
                .<Event>forBoundedOutOfOrderness(Duration.ofMinutes(5))
                .withTimestampAssigner((event, timestamp) ->
                    Instant.parse(event.getTimestamp()).toEpochMilli()
                )
        );

        // Align to UTC hour
        DataStream<Event> aligned = withTimestamps.map(event -> {
            long utcTimestamp = Instant.parse(event.getTimestamp()).toEpochMilli();
            ZonedDateTime utc = Instant.ofEpochMilli(utcTimestamp)
                .atZone(ZoneId.of("UTC"));
            ZonedDateTime aligned = utc.withMinute(0).withSecond(0).withNano(0);
            event.setAlignedTimestamp(aligned.toInstant().toEpochMilli());
            return event;
        });

        aligned.print();
        env.execute("Time Concepts Demo");
    }
}
```

---

## Timestamp Assignment Strategies

### 1. From Record Field (Most Common)
```java
.withTimestampAssigner((event, timestamp) -> event.getEventTime())
```

### 2. From Metadata (Kafka)
```java
.withTimestampAssigner(
    KafkaTimestampAssigner.create()  // Uses Kafka record timestamp
)
```

### 3. Custom Extraction
```java
.withTimestampAssigner((event, timestamp) -> {
    // Custom logic to extract timestamp
    String timeStr = event.getField("time");
    return parseTimestamp(timeStr);
})
```

---

## Common Mistakes

1. **混合时间类型**:
   - ❌ 为事件时间窗口使用处理时间
   - ✅ 对于需要时间顺序正确性的窗口，始终使用事件时间

2. **时区混淆**:
   - ❌ 不转换为 UTC，混合时区
   - ✅ 在摄入时始终转换为 UTC，存储为 UTC，仅在显示时转换为本地时间

3. **时间戳精度**:
   - ❌ 在 SQL 中使用 TIMESTAMP 而不是 TIMESTAMP(3)
   - ✅ 使用 TIMESTAMP(3) 以获得毫秒精度（watermark 需要）

4. **不对齐到边界**:
   - ❌ 14:30 和 14:45 的事件在不同窗口中
   - ✅ 将所有时间戳对齐到小时边界以实现一致的窗口化

5. **ISO 8601 解析错误**:
   - ❌ 不处理时区指示符（Z、+05:00）
   - ✅ 始终使用时区感知解析，转换为 UTC

---

## Mind Trigger: When to Think About This

在以下情况下考虑 Flink 时间概念：
- **设置事件时间处理**: MarketLag 项目的所有窗口都使用事件时间
- **处理时区数据**: RSS feed 和 Polymarket API 可能使用不同时区
- **配置 watermark**: 第 1.5 节要求首先设置事件时间
- **窗口对齐**: 第 1.6 节的窗口需要对齐的时间戳
- **调试窗口问题**: 未对齐的时间戳会导致事件进入错误的窗口

**在 MarketLag 项目中**: 所有时间戳都标准化为 UTC，对齐到小时边界。RSS 事件和 Polymarket 价格都使用 UTC 时间戳以实现一致的窗口化。

---

## Summary

Flink 支持三种时间概念：processing time（系统时钟）、event time（来自数据）和 ingestion time（在 source 处）。MarketLag 使用 event time 以确保时间顺序正确性。所有时间戳都标准化为 UTC 并对齐到小时边界以实现一致的窗口化。理解时间概念是 watermark（第 1.5 节）和窗口（第 1.6 节）的前提。

