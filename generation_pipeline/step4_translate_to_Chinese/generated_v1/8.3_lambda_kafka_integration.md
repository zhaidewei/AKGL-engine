# Lambda-Kafka 集成

**Learning Point**: 8.3 from knowledge_and_skills_needed_v2.md
**Prerequisites**: 8.1 (AWS Lambda)、2.1 (Kafka Connector)、Kafka producer 知识
**Version**: Python 3.9+, kafka-python, confluent-kafka

---

## Definition (Engineering Language)

**Lambda-Kafka Integration**: 将 AWS Lambda 函数连接到 Kafka（Confluent Cloud）以生成消息。Lambda 函数充当 Kafka producers。

**Kafka Producer in Lambda**: 在 Lambda 中使用 kafka-python 或 confluent-kafka 库创建 Kafka producers 并发送消息。

**Confluent Cloud Authentication**: 使用 API key 和 secret 进行 SASL_SSL 身份验证，以安全连接到 Confluent Cloud。

**Error Handling and Retry Logic**: 处理 Kafka producer 错误，为瞬态故障实现重试逻辑。

**Dead Letter Queue**: 用于存储无法发送到主 topics 的失败记录的 Kafka topics。

---

## Plain Language Explanation

将 Lambda-Kafka 集成想象成配送服务：

- **Lambda** = 配送员："获取数据并配送到 Kafka"
- **Kafka Producer** = 配送车："发送消息的车辆"
- **Authentication** = 身份证："证明您被允许配送"
- **Dead Letter Queue** = 失败配送箱："存储失败的配送"

**Why Needed**: MarketLag Lambda 函数将 RSS 事件和 Polymarket 价格发送到 Kafka topics。

---

## Analogy

如果您了解 **Kafka producers**（您了解），Lambda-Kafka 集成是类似的：
- Kafka producer = 带有 Kafka 库的 Lambda（两者都发送消息）
- Producer configuration = Lambda 环境变量（两者都配置连接）
- Error handling = 两者都需要重试逻辑

关键区别：Lambda 在无服务器环境中运行，需要处理冷启动。

---

## Relationship to Already Learned Topics

- **8.1 AWS Lambda**: Lambda 函数包含 Kafka producer 代码
- **2.1 Kafka Connector**: 理解 Kafka producer 配置
- **9.1 Dead Letter Queue**: DLQ 用于失败的 Kafka 消息
- **Kafka**: 您已经了解 Kafka - Lambda 与其集成

---

## Kafka Producer in Lambda: confluent-kafka, kafka-python

### Option 1: confluent-kafka (Recommended)

**Pros**:
- **Official Confluent Library**: 针对 Confluent Cloud 优化
- **Better Performance**: 更高效
- **Better Error Handling**: 更健壮

**Cons**:
- **Larger Size**: 更大的库（使用 Lambda layers）

**MarketLag**: 应该对 Confluent Cloud 使用 confluent-kafka。

### Option 2: kafka-python

**Pros**:
- **Pure Python**: 更易于使用
- **Smaller Size**: 更小的库

**Cons**:
- **Less Optimized**: 未针对 Confluent Cloud 优化
- **Performance**: 可能较慢

**MarketLag**: 可以使用 kafka-python 作为替代方案。

---

## Confluent Cloud Authentication

### Configuration

```python
from confluent_kafka import Producer

# Confluent Cloud authentication
config = {
    'bootstrap.servers': '<confluent-cloud-endpoint>',
    'security.protocol': 'SASL_SSL',
    'sasl.mechanism': 'PLAIN',
    'sasl.username': '<api-key>',
    'sasl.password': '<api-secret>',
    'acks': 'all',  # Wait for all replicas
    'retries': 3,  # Retry on failure
    'enable.idempotence': True  # Exactly-once semantics
}

producer = Producer(config)
```

**MarketLag**: 对 Confluent Cloud 身份验证使用此配置。

### Environment Variables

```python
import os

config = {
    'bootstrap.servers': os.environ['KAFKA_ENDPOINT'],
    'sasl.username': os.environ['KAFKA_API_KEY'],
    'sasl.password': os.environ['KAFKA_API_SECRET'],
    # ... other config
}
```

**MarketLag**: 对环境变量使用安全性（不要硬编码凭据）。

---

## Error Handling and Retry Logic in Lambda

### Basic Error Handling

```python
from confluent_kafka import Producer, KafkaError
import json

def send_to_kafka(topic, messages):
    """
    Send messages to Kafka with error handling.

    Args:
        topic: Kafka topic name
        messages: List of messages to send
    """
    producer = Producer(config)

    def delivery_callback(err, msg):
        """Callback for message delivery."""
        if err:
            print(f"Message delivery failed: {err}")
            # Handle error (retry, DLQ, etc.)
        else:
            print(f"Message delivered: {msg.topic()}[{msg.partition()}]")

    # Send messages
    for message in messages:
        producer.produce(
            topic,
            value=json.dumps(message).encode('utf-8'),
            callback=delivery_callback
        )

    # Wait for all messages to be delivered
    producer.flush(timeout=30)
    producer.close()
```

### Retry Logic

```python
import time

def send_with_retry(topic, messages, max_retries=3):
    """
    Send messages with retry logic.
    """
    for attempt in range(max_retries):
        try:
            send_to_kafka(topic, messages)
            return  # Success
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # Exponential backoff
                time.sleep(wait_time)
            else:
                # Max retries reached, send to DLQ
                send_to_dlq(messages)
                raise
```

**MarketLag**: 为瞬态故障实现重试逻辑。

---

## Dead Letter Queue: Failed Records Handling

### DLQ Concept

**Purpose**: 存储在最大重试次数后无法发送到主 topic 的记录。

**Implementation**: Kafka topic（例如，`dlq.rss.events`、`dlq.polymarket.price_hourly`）

**MarketLag**: 对失败的 RSS 和 Polymarket 记录使用 DLQ topics。

### DLQ Implementation

```python
def send_to_dlq(dlq_topic, failed_messages):
    """
    Send failed messages to dead letter queue.

    Args:
        dlq_topic: DLQ topic name
        failed_messages: List of failed messages
    """
    dlq_producer = Producer(config)

    for message in failed_messages:
        dlq_producer.produce(
            dlq_topic,
            value=json.dumps(message).encode('utf-8')
        )

    dlq_producer.flush()
    dlq_producer.close()
```

**MarketLag**: 将失败的记录发送到 DLQ topics 以供后续分析和重新处理。

---

## Minimum Viable Code

```python
import os
import json
from confluent_kafka import Producer, KafkaError

# Configuration from environment variables
KAFKA_ENDPOINT = os.environ['KAFKA_ENDPOINT']
KAFKA_API_KEY = os.environ['KAFKA_API_KEY']
KAFKA_API_SECRET = os.environ['KAFKA_API_SECRET']
TOPIC = os.environ['KAFKA_TOPIC']
DLQ_TOPIC = os.environ.get('DLQ_TOPIC', f'dlq.{TOPIC}')

def lambda_handler(event, context):
    """
    Lambda handler that sends data to Kafka.
    """
    # Kafka producer configuration
    config = {
        'bootstrap.servers': KAFKA_ENDPOINT,
        'security.protocol': 'SASL_SSL',
        'sasl.mechanism': 'PLAIN',
        'sasl.username': KAFKA_API_KEY,
        'sasl.password': KAFKA_API_SECRET,
        'acks': 'all',
        'retries': 3,
        'enable.idempotence': True
    }

    producer = Producer(config)
    failed_messages = []

    def delivery_callback(err, msg):
        if err:
            print(f"Delivery failed: {err}")
            failed_messages.append(msg.value())
        else:
            print(f"Delivered: {msg.topic()}[{msg.partition()}]")

    # Fetch data
    data = fetch_data()

    # Send to Kafka
    for item in data:
        producer.produce(
            TOPIC,
            value=json.dumps(item).encode('utf-8'),
            callback=delivery_callback
        )

    # Wait for delivery
    producer.flush(timeout=30)
    producer.close()

    # Send failed messages to DLQ
    if failed_messages:
        send_to_dlq(DLQ_TOPIC, failed_messages)

    return {
        'statusCode': 200,
        'body': json.dumps({
            'sent': len(data) - len(failed_messages),
            'failed': len(failed_messages)
        })
    }
```

---

## Common Mistakes

1. **Not closing producer**:
   - ❌ Producer 未关闭，连接泄漏
   - ✅ 始终调用 `producer.close()` 或使用上下文管理器

2. **Not flushing**:
   - ❌ 消息未刷新，可能未发送
   - ✅ 在关闭前始终调用 `producer.flush()`

3. **Wrong authentication**:
   - ❌ 缺少 SASL_SSL 配置
   - ✅ 始终为 Confluent Cloud 配置 SASL_SSL

4. **No error handling**:
   - ❌ 没有重试逻辑，失败时消息丢失
   - ✅ 实现重试逻辑和 DLQ

5. **Hardcoding credentials**:
   - ❌ 代码中的 API keys（安全风险）
   - ✅ 对凭据使用环境变量

---

## Mind Trigger: When to Think About This

在以下情况下考虑 Lambda-Kafka 集成：
- **实现 producers**: MarketLag Lambda 函数发送到 Kafka
- **配置身份验证**: Confluent Cloud 需要 SASL_SSL
- **错误处理**: 实现重试逻辑和 DLQ（第 9.1 节）
- **Producer 库**: 选择 confluent-kafka 或 kafka-python
- **Lambda layers**: 在 Lambda layers 中打包 Kafka 库

**在 MarketLag 项目中**: Lambda 函数使用 confluent-kafka 将 RSS 事件和 Polymarket 价格发送到 Kafka。使用 SASL_SSL 身份验证、重试逻辑和 DLQ 处理失败消息。理解 Lambda-Kafka 集成对于 data producer 实现至关重要。

---

## Summary

Lambda-Kafka 集成使 Lambda 函数能够生成消息到 Kafka。使用 confluent-kafka 或 kafka-python 库。Confluent Cloud 需要使用 API key/secret 进行 SASL_SSL 身份验证。实现错误处理、重试逻辑和 dead letter queues 处理失败消息。MarketLag 对 RSS 和 Polymarket producers 使用此模式。理解 Lambda-Kafka 集成对于 data producer 实现至关重要。
