# 项目特定的错误处理模式

**Learning Point**: 9.4 from knowledge_and_skills_needed_v2.md
**Prerequisites**: 9.1 (DLQ), 9.2 (Data Validation), 9.3 (Exception Handling), 3.3 (Equi-Join)
**Version**: Flink 2.2.0

---

## Definition (Engineering Language)

**Project-Specific Error Handling Patterns**: Error handling strategies tailored to MarketLag project's specific scenarios and requirements.

**Missing RSS Data in Window**: When no RSS events arrive in a time window, skip the window (no output) and log a warning.

**Missing Price Data in Join**: When price data is missing in equi-join, use LEFT JOIN to handle missing prices, set price_delta = 0.

**API Rate Limits in Lambda**: When API rate limits are hit, implement exponential backoff retry, record to DLQ after max retries.

**Schema Registry Evolution**: Handle schema compatibility and version management when schemas evolve over time.

---

## Plain Language Explanation

将项目特定的错误处理想象成自定义安全规则：

- **Missing RSS Data** = 没有新闻："这个小时没有 RSS 事件，跳过窗口"
- **Missing Price Data** = 没有价格："价格缺失，使用默认值（delta = 0）"
- **API Rate Limits** = 请求过多："等待并重试，如果仍然失败则发送到 DLQ"
- **Schema Evolution** = Schema 变化："处理新旧 schema 版本"

**Why Needed**: MarketLag 有需要定制处理的特定错误场景。

---

## Analogy

如果您了解 **error handling patterns**（您了解），项目特定的模式是类似的：
- Generic error handling = Project-specific patterns（两者都处理错误）
- Error recovery = Custom recovery logic（两者都从错误中恢复）

关键区别：项目特定的模式是针对 MarketLag 独特场景定制的。

---

## Relationship to Already Learned Topics

- **9.1 Dead Letter Queue**: DLQ 用于 API 速率限制失败
- **9.2 Data Validation**: 验证处理缺失数据
- **9.3 Exception Handling**: 异常处理实现这些模式
- **3.3 Equi-Join**: 在 joins 中处理缺失的价格数据

---

## Missing RSS Data in Window: Skip the Window (No Output), Log Warning

### Scenario

**Problem**: No RSS events arrive in a time window (e.g., no news in that hour).

**MarketLag Behavior**: Skip the window (no output), log warning.

### Implementation

```sql
-- Job 1: RSS Signal Aggregation
SELECT
    market_slug,
    TUMBLE_START(published_at, INTERVAL '1' HOUR) as window_start,
    COUNT(*) as mention_count,
    AVG(article_score * source_weight) as source_weighted_signal
FROM rss_events
WHERE published_at IS NOT NULL
GROUP BY market_slug, TUMBLE(published_at, INTERVAL '1' HOUR)
HAVING COUNT(*) > 0  -- Only output windows with data
```

**Behavior**: Windows with no data don't produce output (HAVING clause filters them out).

### Logging

```java
// In Flink, log warning for empty windows
if (windowCount == 0) {
    log.warn("No RSS events in window: market={}, window={}", market, window);
}
```

**MarketLag**: Skips empty windows, logs warnings for monitoring.

---

## Missing Price Data in Join: Use LEFT JOIN to Handle Missing Prices, Set price_delta = 0

### Scenario

**Problem**: Price data missing for a market/time window in equi-join.

**MarketLag Behavior**: Use LEFT JOIN, set price_delta = 0 when price missing.

### Implementation

```sql
-- Job 3: Use LEFT JOIN to handle missing prices
SELECT
    r.market_slug,
    r.window_start,
    r.source_weighted_signal as rss_signal,
    COALESCE(p.price, 0.0) as price,
    COALESCE(p.price_delta, 0.0) as price_delta,  -- Default to 0 if missing
    -- Calculate signal_delta
    (r.source_weighted_signal - LAG(r.source_weighted_signal)
      OVER (PARTITION BY r.market_slug ORDER BY r.window_start)) as signal_delta
FROM rss_signals_hourly r
LEFT JOIN polymarket_price_hourly p
ON r.market_slug = p.market_slug
  AND r.window_start = p.event_time
WHERE r.source_weighted_signal IS NOT NULL
```

**Key Points**:
- **LEFT JOIN**: Returns all RSS signals, even if price missing
- **COALESCE**: Sets price_delta = 0.0 when price data missing
- **Continue Processing**: Job continues despite missing prices

**MarketLag**: Uses LEFT JOIN to handle missing price data gracefully.

---

## API Rate Limits in Lambda: Exponential Backoff Retry, Record to DLQ After Max Retries

### Scenario

**Problem**: RSS.app or Polymarket API returns rate limit error (429).

**MarketLag Behavior**: Exponential backoff retry, send to DLQ after max retries.

### Implementation

```python
import time
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

def fetch_with_retry(url, max_retries=3):
    """
    Fetch with exponential backoff retry.
    """
    session = requests.Session()
    retry_strategy = Retry(
        total=max_retries,
        backoff_factor=1,  # Exponential: 1s, 2s, 4s
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET", "POST"]
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)

    try:
        response = session.get(url, timeout=30)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 429:
            # Rate limit hit, retry with backoff
            if retry_strategy.total > 0:
                wait_time = 2 ** (max_retries - retry_strategy.total)
                time.sleep(wait_time)
                return fetch_with_retry(url, max_retries - 1)
            else:
                # Max retries reached, send to DLQ
                send_to_dlq({'url': url, 'error': 'Rate limit exceeded'})
                raise
        else:
            raise
```

**MarketLag**: Implements exponential backoff for API rate limits, sends to DLQ after max retries.

---

## Schema Registry Evolution: Handle Schema Compatibility, Version Management

### Scenario

**Problem**: Schema changes over time (e.g., adding new fields to RSS events).

**MarketLag Behavior**: Handle schema compatibility, manage versions.

### Backward Compatibility

**Strategy**: New schema is backward compatible (adds optional fields).

**Result**: Old consumers can still read new data (ignore new fields).

**MarketLag**: Uses backward-compatible schema evolution.

### Forward Compatibility

**Strategy**: Old schema is forward compatible (removes optional fields).

**Result**: New consumers can read old data (handle missing fields).

**MarketLag**: Can use forward-compatible evolution if needed.

### Version Management

```python
# In Lambda, handle schema versions
def process_record(record, schema_version):
    """
    Process record based on schema version.
    """
    if schema_version == 1:
        # Old schema
        return process_v1(record)
    elif schema_version == 2:
        # New schema
        return process_v2(record)
    else:
        # Unknown version, send to DLQ
        send_to_dlq(record)
```

**MarketLag**: Manages schema versions, handles compatibility.

---

## Minimum Viable Code

```python
# Project-specific error handling in Lambda
def lambda_handler(event, context):
    """
    Lambda handler with project-specific error handling.
    """
    try:
        # Fetch data with retry
        data = fetch_with_retry(api_url, max_retries=3)

        # Validate data
        validated_data = []
        for item in data:
            if validate_record(item):
                validated_data.append(item)
            else:
                # Invalid record, send to DLQ
                send_to_dlq(item)

        # Send to Kafka
        if validated_data:
            send_to_kafka(validated_data)
        else:
            # No valid data, log warning
            log.warn("No valid data in this run")

        return {'statusCode': 200}

    except RateLimitError:
        # Rate limit after retries, already sent to DLQ
        return {'statusCode': 429, 'body': 'Rate limit exceeded'}
    except Exception as e:
        log.error(f"Unexpected error: {e}")
        return {'statusCode': 500, 'body': str(e)}
```

---

## Common Mistakes

1. **Not handling missing data**:
   - ❌ Job fails when data missing
   - ✅ Handle missing data gracefully (skip, default, etc.)

2. **Not using LEFT JOIN**:
   - ❌ INNER JOIN drops records when price missing
   - ✅ Use LEFT JOIN to preserve RSS signals

3. **Not implementing retry**:
   - ❌ API rate limit causes immediate failure
   - ✅ Implement exponential backoff retry

4. **Not handling schema evolution**:
   - ❌ Schema changes break consumers
   - ✅ Use compatible schema evolution

5. **Not logging warnings**:
   - ❌ Silent failures, issues unnoticed
   - ✅ Log warnings for monitoring

---

## Mind Trigger: When to Think About This

Think about project-specific error handling when:
- **Designing error handling**: MarketLag has specific error scenarios
- **Missing data**: Handle missing RSS or price data gracefully
- **API failures**: Handle rate limits and API errors
- **Schema changes**: Handle schema evolution over time
- **Monitoring**: Log warnings and errors for monitoring

**In MarketLag project**: Handles missing RSS data (skip window), missing price data (LEFT JOIN, price_delta = 0), API rate limits (exponential backoff, DLQ), and schema evolution (compatibility). Understanding project-specific patterns is essential for robust error handling.

---

## Summary

Project-specific error handling patterns address MarketLag's unique scenarios. Missing RSS data: skip window, log warning. Missing price data: use LEFT JOIN, set price_delta = 0. API rate limits: exponential backoff retry, DLQ after max retries. Schema evolution: handle compatibility and version management. Understanding project-specific patterns is essential for robust error handling.

