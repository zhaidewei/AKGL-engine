# Kafka 分区和 Flink 并行度

**Learning Point**: 2.4 from knowledge_and_skills_needed_v2.md
**Prerequisites**: 1.1 (Flink Architecture), 2.1 (Kafka Connector), Kafka partitioning knowledge
**Version**: Flink 2.2.0

---

## 工程化定义

**Kafka Partition Key**: 用于确定消息写入哪个 Kafka 分区的键。具有相同键的消息进入同一分区。

**Flink keyBy**: 按键对流进行分区的 Flink 算子。具有相同键的事件由同一 subtask 处理。

**Partition Assignment**: Kafka 分区如何分配给 Flink subtasks。一个 Flink subtask 可以从多个分区读取，但一个分区只能由一个 subtask 读取。

**Parallelism**: 每个算子的并行 subtasks 数量。应匹配或为 Kafka 分区数量的因子，以实现最佳分布。

---

## 通俗解释

将 Kafka 分区和 Flink 并行度视为餐厅：

- **Kafka Partitions** = 服务台：每个台处理一部分订单
- **Partition Key** = 订单路由：同一客户的订单进入同一台
- **Flink Parallelism** = 工作人员：处理订单的工作人员数量
- **keyBy** = 工作人员分配：同一客户的订单由同一工作人员处理

**为什么重要**: MarketLag 使用 `market_slug` 作为 `rss.events` 的分区键，确保同一市场的所有事件一起处理。

---

## 类比理解

如果您了解 **Spark 的分区**（您了解），Flink 的方法类似：
- Spark partitionBy = Flink keyBy（两者都按键分区）
- Spark partitions = Flink subtasks（两者都并行处理）
- Kafka 分区映射到处理分区

关键区别：Flink 的 keyBy 确保所有具有相同键的事件进入同一 subtask，从而启用键控状态。

---

## 与已学内容的关系

- **1.1 Flink Architecture**: 并行度决定 subtasks 数量
- **2.1 Kafka Connector**: KafkaSource 从分区读取
- **1.7 State Types**: 键控状态需要 keyBy（相同键 = 相同状态）
- **Kafka**: 您已经了解 Kafka 分区 - Flink 遵循它

---

## 伪代码（基于源码）

Based on Flink 2.2.0 source code:

```java
// Partition assignment (simplified)
class KafkaSourceFunction {
    void assignPartitions(List<KafkaPartition> partitions, int parallelism) {
        // Assign partitions to subtasks
        for (int i = 0; i < partitions.size(); i++) {
            int subtaskIndex = i % parallelism;
            assignPartitionToSubtask(partitions.get(i), subtaskIndex);
        }
    }
}

// keyBy partitioning (simplified)
class KeyByOperator {
    int selectChannel(Record record, int parallelism) {
        Object key = extractKey(record);
        int hash = key.hashCode();
        return Math.abs(hash) % parallelism;  // Route to subtask
    }
}
```

---

## 源码参考

**Local Path**: `generation_pipeline/step0_context/source_codes/flink/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/source/split/KafkaPartitionSplit.java`

**GitHub URL**: https://github.com/apache/flink/blob/release-2.2/flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/connector/kafka/source/split/KafkaPartitionSplit.java

---

## Kafka 分区键与 Flink keyBy 的关系

### Kafka Partition Key

Kafka 使用分区键确定分区：
- 相同键 → 相同分区
- 不同键 → 分布在多个分区

**MarketLag Pattern**: `market_slug` 作为 `rss.events` 的分区键
- "fed-hike-january" 的所有 RSS 事件进入同一 Kafka 分区
- 确保每个市场的顺序

### Flink keyBy

Flink keyBy 按键对流进行分区：
- 相同键 → 相同 subtask
- 不同键 → 分布在多个 subtasks

**关系**: 如果 Kafka 分区键 = Flink keyBy 键，则：
- 来自同一 Kafka 分区的事件进入同一 Flink subtask
- 保持顺序并启用键控状态

---

## 分区分配策略

### Automatic Assignment (Default)

Flink 自动将 Kafka 分区分配给 subtasks：
- Partition 0 → Subtask 0
- Partition 1 → Subtask 1
- Partition 2 → Subtask 0（如果 parallelism=2，则循环）
- 等等

**最优**: 并行度应等于或为分区数量的因子。

### Manual Assignment (Advanced)

可以手动分配分区，但通常不需要。

---

## 并行度与分区分布

### Optimal Parallelism

**经验法则**: 将并行度设置为等于 Kafka 分区数量（或因子）。

**Example**:
- Kafka topic 有 4 个分区
- Flink parallelism = 4 → 每个 subtask 读取 1 个分区（最优）
- Flink parallelism = 2 → 每个 subtask 读取 2 个分区（可接受）
- Flink parallelism = 8 → 某些 subtasks 空闲（浪费）

**MarketLag Project**: 使用 parallelism=2（对于 2 CFU）。Kafka topics 应该有 2 或 4 个分区以实现最佳分布。

### Partition Distribution Example

**4 个分区，Parallelism=2**:
- Subtask 0: 读取分区 0、2
- Subtask 1: 读取分区 1、3

**4 个分区，Parallelism=4**:
- Subtask 0: 读取分区 0
- Subtask 1: 读取分区 1
- Subtask 2: 读取分区 2
- Subtask 3: 读取分区 3

---

## 项目实践：MarketLag 分区策略

### RSS Events Topic

**Partition Key**: `market_slug`
- All events for same market → Same partition
- Ensures ordering per market
- Enables efficient keyed processing

**Kafka Producer (Lambda)**:
```python
producer.send('rss.events',
              key=market_slug,  # Partition key
              value=json.dumps(event))
```

**Flink Processing**:
```sql
-- In Flink SQL, keyBy happens automatically in GROUP BY
SELECT market_slug, ...
FROM rss_events
GROUP BY market_slug, TUMBLE(...)
-- Events with same market_slug processed together
```

### Polymarket Price Topic

**Partition Key**: `market_slug|outcome` (e.g., "fed-hike-january|YES")
- Prices for same market+outcome → Same partition
- Enables efficient joins with RSS signals

**Kafka Producer (Lambda)**:
```python
partition_key = f"{market_slug}|{outcome}"
producer.send('polymarket.price_hourly',
              key=partition_key,
              value=json.dumps(price_event))
```

---

## 最小可用代码

```java
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

// Set parallelism (should match or be factor of Kafka partition count)
env.setParallelism(4);  // If Kafka topic has 4 partitions

// Kafka source automatically distributes partitions
KafkaSource<String> source = KafkaSource.<String>builder()
    .setBootstrapServers("localhost:9092")
    .setTopics("rss.events")  // Has 4 partitions
    .setGroupId("flink-consumer")
    .setStartingOffsets(OffsetsInitializer.latest())
    .setValueOnlyDeserializer(new SimpleStringSchema())
    .build();

DataStream<String> stream = env.fromSource(source, ...);

// keyBy ensures same key goes to same subtask
stream.keyBy(event -> extractMarketSlug(event))
    .process(...);  // Keyed state accessible per key
```

---

## 常见错误

1. **并行度与分区不匹配**:
   - ❌ Parallelism=8，partitions=4（浪费，某些 subtasks 空闲）
   - ✅ 将并行度设置为等于或为分区数量的因子

2. **分区键不匹配**:
   - ❌ Kafka 分区键 ≠ Flink keyBy 键（导致重新 shuffle）
   - ✅ 两者使用相同的键（MarketLag 使用 market_slug）

3. **分区太多**:
   - ❌ 小数据量使用 100 个分区（开销）
   - ✅ MVP 使用 2-4 个分区（MarketLag 模式）

4. **不理解 keyBy**:
   - ❌ 在不理解的情况下使用 keyBy 会导致 shuffle
   - ✅ keyBy 重新分区数据 - 仅在需要状态操作时使用

5. **分区倾斜**:
   - ❌ 一个分区的数据远多于其他分区
   - ✅ 选择均匀分布数据的分区键（market_slug 很好）

---

## 触发点：什么时候想到这个概念

在以下情况下考虑 Kafka 分区和 Flink 并行度：
- **设置 Kafka topics**: 选择分区数量和分区键
- **配置 Flink 并行度**: 应匹配分区数量
- **设计数据流**: MarketLag 使用 market_slug 作为分区键
- **性能调优**: 最优并行度提高吞吐量
- **有状态处理**: keyBy 需要用于键控状态（第 1.7 节）

**在 MarketLag 项目中**: 对 `rss.events` 使用 `market_slug` 作为分区键，对 `polymarket.price_hourly` 使用 `market_slug|outcome`。Parallelism=2 匹配 2 CFU 分配。理解分区确保高效的数据分布和键控状态访问。

---

## 小结

Kafka 分区键确定消息进入哪个分区。Flink keyBy 按键对流进行分区，确保相同键进入同一 subtask。并行度应匹配或为 Kafka 分区数量的因子。MarketLag 对 RSS 事件使用 `market_slug` 作为分区键，对价格使用 `market_slug|outcome`。理解分区和并行度对于有状态流处理的性能和正确性至关重要。

