# Keyword Scoring System

**Learning Point**: 12.3 from knowledge_and_skills_needed_v2.md
**Prerequisites**: Understanding of text processing, aggregations
**Version**: Flink 2.2.0

---

## Definition (Engineering Language)

**Keyword Scoring System**: A mechanism to convert RSS article content into numerical signals by assigning weights to keywords and aggregating their occurrences.

**Keyword Weights**: Numerical values assigned to keywords indicating their importance. Positive weights indicate positive sentiment, negative weights indicate negative sentiment.

**Keyword Occurrence Counting**: Counting how many times each keyword appears in an article.

**Keyword Score Aggregation**: Summing weighted keyword occurrences to produce an article score. Formula: `SUM(weight × count)` per article.

---

## Plain Language Explanation

Think of keyword scoring like a sentiment analyzer:

- **Keyword Weights** = Importance scores: "Fed" = 2.0 (very important), "dovish" = -1.5 (negative)
- **Occurrence Counting** = How many times: "Fed appears 3 times in this article"
- **Score Aggregation** = Total score: "Fed (3×2.0) + hike (2×2.0) = 10.0 article score"

**Why Needed**: MarketLag converts RSS article text into numerical signals. Keyword scoring quantifies article sentiment and importance.

---

## Analogy

If you know **TF-IDF** or **sentiment analysis** (which you do), keyword scoring is similar:
- TF-IDF weights = Keyword weights (both assign importance)
- Word frequency = Keyword occurrence counting (both count occurrences)
- Document score = Article score (both aggregate to produce score)

Key difference: Keyword scoring uses domain-specific weights (Fed, rate, hike) rather than statistical weights.

---

## Relationship to Already Learned Topics

- **12.4 Source Weighting**: Article scores are weighted by source credibility
- **3.1 Window Functions**: Keyword scores aggregated over windows
- **Text Processing**: You already know text processing - keyword scoring applies it

---

## Pseudocode (From Project Design)

Based on MarketLag project design:

```python
# Keyword weights (simplified)
KEYWORD_WEIGHTS = {
    'Fed': 2.0,
    'rate': 1.5,
    'hike': 2.0,
    'dovish': -1.5
}

# Keyword scoring (simplified)
def calculate_article_score(article_text, keywords):
    score = 0
    for keyword, weight in KEYWORD_WEIGHTS.items():
        count = article_text.lower().count(keyword.lower())
        score += weight * count
    return score
```

---

## Source Code References

**Project Design**: `generation_pipeline/step1_output_project_design/output_project_design_v5.md`

**Implementation**: This is implemented in MarketLag RSS producer (Lambda function, section 8.1).

---

## Keyword Weights: Positive vs Negative

### Positive Keywords (Market-Bullish)

**Weights**:
- **Fed**: 2.0 (high importance)
- **rate**: 1.5 (medium importance)
- **hike**: 2.0 (high importance)

**Meaning**: These keywords indicate positive market movement (rate hikes, Fed actions).

### Negative Keywords (Market-Bearish)

**Weights**:
- **dovish**: -1.5 (negative sentiment)

**Meaning**: This keyword indicates negative market movement (dovish = less aggressive).

### Weight Selection

**Criteria**:
- **Importance**: How much does this keyword affect market?
- **Sentiment**: Positive (rate hike) vs negative (dovish)
- **Domain Knowledge**: Based on financial market understanding

**MarketLag**: Uses these weights for Fed-related market analysis.

---

## Keyword Occurrence Counting

### Counting Process

1. **Text Normalization**: Convert to lowercase for case-insensitive matching
2. **Pattern Matching**: Count keyword occurrences in article text
3. **Aggregation**: Sum counts per keyword

### Example

**Article Text**: "Fed raises rates. Fed officials signal more hikes."

**Counts**:
- "Fed": 2 occurrences
- "rate": 1 occurrence (in "rates")
- "hike": 1 occurrence (in "hikes")
- "dovish": 0 occurrences

---

## Keyword Score Aggregation: SUM(weight × count) per Article

### Formula

```
article_score = SUM(keyword_weight × keyword_count) for all keywords
```

### Example Calculation

**Article**: "Fed raises rates. Fed officials signal more hikes."

**Counts and Weights**:
- Fed: count=2, weight=2.0 → score = 2 × 2.0 = 4.0
- rate: count=1, weight=1.5 → score = 1 × 1.5 = 1.5
- hike: count=1, weight=2.0 → score = 1 × 2.0 = 2.0
- dovish: count=0, weight=-1.5 → score = 0 × (-1.5) = 0.0

**Article Score**: 4.0 + 1.5 + 2.0 + 0.0 = **7.5**

### MarketLag Implementation

```python
# In RSS producer (Lambda)
def calculate_keyword_score(article_text, keywords):
    score = 0.0
    text_lower = article_text.lower()

    for keyword, weight in KEYWORD_WEIGHTS.items():
        count = text_lower.count(keyword.lower())
        score += weight * count

    return score
```

---

## Minimum Viable Code

```python
# Keyword scoring implementation
KEYWORD_WEIGHTS = {
    'Fed': 2.0,
    'rate': 1.5,
    'hike': 2.0,
    'dovish': -1.5
}

def calculate_article_score(article_text):
    """
    Calculate article score based on keyword weights and occurrences.

    Args:
        article_text: Article text content

    Returns:
        float: Article score
    """
    score = 0.0
    text_lower = article_text.lower()

    for keyword, weight in KEYWORD_WEIGHTS.items():
        # Count occurrences (case-insensitive)
        count = text_lower.count(keyword.lower())
        # Add weighted score
        score += weight * count

    return score

# Example
article = "Fed raises rates. Fed officials signal more hikes."
score = calculate_article_score(article)
print(f"Article score: {score}")  # Output: 7.5
```

---

## Common Mistakes

1. **Case sensitivity**:
   - ❌ Case-sensitive matching ("Fed" vs "fed")
   - ✅ Use case-insensitive matching: `text.lower().count(keyword.lower())`

2. **Partial word matches**:
   - ❌ Matching "rate" in "operate" (partial match)
   - ✅ Use word boundaries or whole-word matching

3. **Missing keywords**:
   - ❌ Not counting all relevant keywords
   - ✅ Define comprehensive keyword list

4. **Wrong weights**:
   - ❌ Using equal weights for all keywords
   - ✅ Use domain knowledge to assign appropriate weights

5. **Not normalizing**:
   - ❌ Raw counts without normalization
   - ✅ Consider article length normalization if needed

---

## Mind Trigger: When to Think About This

Think about keyword scoring when:
- **Processing RSS articles**: MarketLag converts article text to signals
- **Designing weights**: Choosing appropriate keyword weights
- **Aggregating scores**: Section 12.4 covers source-weighted aggregation
- **Tuning system**: Adjusting weights based on results
- **Extending keywords**: Adding new keywords as project evolves

**In MarketLag project**: Keyword scoring converts RSS article content into numerical signals. Article scores are then weighted by source credibility (section 12.4) and aggregated over windows (Job 1). Understanding keyword scoring is essential for signal generation.

---

## Summary

Keyword scoring system converts RSS article content into numerical signals by assigning weights to keywords and aggregating occurrences. Positive keywords (Fed=2.0, rate=1.5, hike=2.0) indicate positive sentiment, negative keywords (dovish=-1.5) indicate negative sentiment. Article score = SUM(weight × count) for all keywords. MarketLag implements this in RSS producer (Lambda). Understanding keyword scoring is essential for signal generation in the project.

