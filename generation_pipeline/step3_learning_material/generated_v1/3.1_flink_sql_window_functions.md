# Flink SQL Window Functions

**Learning Point**: 3.1 from knowledge_and_skills_needed_v2.md
**Prerequisites**: 1.3 (Table API/SQL), 1.6 (Windows), SQL window functions knowledge
**Version**: Flink 2.2.0

---

## Definition (Engineering Language)

**TUMBLE Window Function**: Flink SQL function for creating tumbling (non-overlapping) time windows. Groups events into fixed-size, non-overlapping time intervals.

**TUMBLE_START**: Extracts the start timestamp of a tumbling window.

**TUMBLE_END**: Extracts the end timestamp of a tumbling window.

**Window Aggregation**: Applying aggregate functions (COUNT, SUM, AVG, etc.) over windowed data.

**GROUP BY Window**: Grouping by both key and window to aggregate per key per window.

---

## Plain Language Explanation

Think of TUMBLE window functions like hourly reports:

- **TUMBLE** = Hour buckets: Group events into 1-hour buckets
- **TUMBLE_START** = Bucket start time: "This bucket starts at 14:00"
- **TUMBLE_END** = Bucket end time: "This bucket ends at 15:00"
- **Aggregation** = Summarize: Count events, sum values in each bucket

**Why Needed**: MarketLag Job 1 aggregates RSS events hourly - all events in the same hour are grouped together and aggregated.

---

## Analogy

If you know **SQL window functions** (which you do), Flink's TUMBLE is similar but for streaming:
- SQL `OVER (PARTITION BY ... ORDER BY ... ROWS BETWEEN ...)` = Flink TUMBLE (but time-based, not row-based)
- SQL aggregates over partitions = Flink aggregates over windows

Key difference: Flink windows are time-based and continuous (unbounded), SQL windows are row-based and bounded.

---

## Relationship to Already Learned Topics

- **1.6 Windows**: TUMBLE creates tumbling windows (covered in section 1.6)
- **1.3 Table API/SQL**: TUMBLE is a Flink SQL function
- **1.5 Watermarks**: Windows use watermarks to trigger (section 1.5)
- **SQL Aggregations**: You already know COUNT, SUM, AVG from SQL

---

## Pseudocode (From Source Code)

Based on Flink 2.2.0 source code:

```sql
-- TUMBLE function (simplified parsing)
TUMBLE(time_col, INTERVAL '1' HOUR)
-- Parses to: TumblingWindowAssigner with 1-hour size
-- Groups events into [00:00, 01:00), [01:00, 02:00), etc.

-- TUMBLE_START (simplified)
TUMBLE_START(time_col, INTERVAL '1' HOUR)
-- Returns: Window start timestamp for current window

-- TUMBLE_END (simplified)
TUMBLE_END(time_col, INTERVAL '1' HOUR)
-- Returns: Window end timestamp for current window
```

---

## Source Code References

**Local Path**: `generation_pipeline/step0_context/source_codes/flink/flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/functions/SqlLikeWindowFunction.java`

**GitHub URL**: https://github.com/apache/flink/blob/release-2.2/flink-table/flink-table-api-java/src/main/java/org/apache/flink/table/functions/SqlLikeWindowFunction.java

---

## TUMBLE Window Function Syntax

### Basic TUMBLE Syntax

```sql
SELECT
    key,
    TUMBLE_START(time_col, INTERVAL '1' HOUR) as window_start,
    TUMBLE_END(time_col, INTERVAL '1' HOUR) as window_end,
    COUNT(*) as count
FROM table
GROUP BY key, TUMBLE(time_col, INTERVAL '1' HOUR);
```

**Key Points**:
- `TUMBLE(time_col, INTERVAL 'N' UNIT)` in GROUP BY creates windows
- `TUMBLE_START` and `TUMBLE_END` extract window boundaries
- Must group by both key and TUMBLE window

### MarketLag Job 1 Example

```sql
SELECT
    market_slug,
    TUMBLE_START(published_at, INTERVAL '1' HOUR) as window_start,
    TUMBLE_END(published_at, INTERVAL '1' HOUR) as window_end,
    COUNT(*) as mention_count,
    SUM(keyword_score) as keyword_score,
    AVG(article_score * source_weight) as source_weighted_signal
FROM rss_events
GROUP BY market_slug, TUMBLE(published_at, INTERVAL '1' HOUR);
```

**This is the exact pattern used in MarketLag Job 1**.

---

## Window Aggregation: COUNT, SUM, AVG Over Windows

### COUNT Over Windows

```sql
SELECT
    key,
    TUMBLE_START(time_col, INTERVAL '1' HOUR) as window_start,
    COUNT(*) as event_count
FROM table
GROUP BY key, TUMBLE(time_col, INTERVAL '1' HOUR);
```

Counts number of events per key per window.

### SUM Over Windows

```sql
SELECT
    key,
    TUMBLE_START(time_col, INTERVAL '1' HOUR) as window_start,
    SUM(value) as total_value
FROM table
GROUP BY key, TUMBLE(time_col, INTERVAL '1' HOUR);
```

Sums values per key per window.

### AVG Over Windows

```sql
SELECT
    key,
    TUMBLE_START(time_col, INTERVAL '1' HOUR) as window_start,
    AVG(value) as avg_value
FROM table
GROUP BY key, TUMBLE(time_col, INTERVAL '1' HOUR);
```

Averages values per key per window.

**MarketLag Job 1**: Uses COUNT (mention_count), SUM (keyword_score), and AVG (source_weighted_signal).

---

## Window Start and End Time Extraction

### TUMBLE_START

Extracts the start timestamp of the window:

```sql
TUMBLE_START(published_at, INTERVAL '1' HOUR)
-- For event at 14:30:00, returns: 14:00:00
-- For event at 15:15:00, returns: 15:00:00
```

### TUMBLE_END

Extracts the end timestamp of the window:

```sql
TUMBLE_END(published_at, INTERVAL '1' HOUR)
-- For event at 14:30:00, returns: 15:00:00
-- For event at 15:15:00, returns: 16:00:00
```

**Note**: Window end is exclusive (not inclusive). Window [14:00, 15:00) includes 14:00:00 but not 15:00:00.

---

## Grouping by Window and Key

### GROUP BY Syntax

```sql
GROUP BY key, TUMBLE(time_col, INTERVAL '1' HOUR)
```

**Important**: Must group by both:
1. **Key** (e.g., market_slug): Groups events by key
2. **TUMBLE window**: Groups events by time window

### Why Both Are Needed

- **Key**: Ensures aggregation is per key (e.g., per market)
- **Window**: Ensures aggregation is per time period (e.g., per hour)

**MarketLag Job 1**: Groups by `market_slug` (key) and `TUMBLE(published_at, INTERVAL '1' HOUR)` (window).

---

## Minimum Viable Code

```java
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;

public class WindowFunctionsDemo {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);

        // Create source table
        tableEnv.executeSql(
            "CREATE TABLE events (" +
            "  key STRING," +
            "  value DOUBLE," +
            "  event_time TIMESTAMP(3)," +
            "  WATERMARK FOR event_time AS event_time - INTERVAL '5' MINUTE" +
            ") WITH (" +
            "  'connector' = 'kafka'," +
            "  'topic' = 'events'," +
            "  'properties.bootstrap.servers' = 'localhost:9092'," +
            "  'format' = 'json'" +
            ")"
        );

        // Window aggregation
        tableEnv.executeSql(
            "CREATE TABLE windowed_results AS " +
            "SELECT " +
            "  key," +
            "  TUMBLE_START(event_time, INTERVAL '1' HOUR) as window_start," +
            "  TUMBLE_END(event_time, INTERVAL '1' HOUR) as window_end," +
            "  COUNT(*) as count," +
            "  SUM(value) as total," +
            "  AVG(value) as avg_value " +
            "FROM events " +
            "GROUP BY key, TUMBLE(event_time, INTERVAL '1' HOUR)"
        );

        env.execute("Window Functions Demo");
    }
}
```

---

## Common Mistakes

1. **Missing TUMBLE in GROUP BY**:
   - ❌ `GROUP BY key` (no window grouping)
   - ✅ `GROUP BY key, TUMBLE(time_col, INTERVAL '1' HOUR)`

2. **Wrong time column**:
   - ❌ Using processing time instead of event time
   - ✅ Use event time column with WATERMARK declaration

3. **Missing WATERMARK**:
   - ❌ Windows never trigger without watermarks
   - ✅ Always declare WATERMARK in CREATE TABLE (section 1.5)

4. **Wrong window size syntax**:
   - ❌ `INTERVAL 1 HOUR` (missing quotes)
   - ✅ `INTERVAL '1' HOUR` (quotes required)

5. **Not understanding window boundaries**:
   - ❌ Expecting inclusive end time
   - ✅ Window end is exclusive: [start, end)

---

## Mind Trigger: When to Think About This

Think about Flink SQL window functions when:
- **Writing Job 1**: MarketLag Job 1 uses TUMBLE for hourly RSS aggregation
- **Time-based aggregations**: Need to aggregate events over time periods
- **Window boundaries**: Understanding TUMBLE_START and TUMBLE_END
- **GROUP BY windows**: Must group by both key and TUMBLE window
- **Watermark integration**: Windows trigger when watermark passes window end

**In MarketLag project**: Job 1 uses TUMBLE window functions to aggregate RSS events hourly. Groups by market_slug and TUMBLE(published_at, INTERVAL '1' HOUR), calculating mention_count, keyword_score, and source_weighted_signal per market per hour.

---

## Summary

Flink SQL TUMBLE window functions create tumbling (non-overlapping) time windows. TUMBLE_START and TUMBLE_END extract window boundaries. Window aggregations (COUNT, SUM, AVG) are applied per key per window. Must group by both key and TUMBLE window. MarketLag Job 1 uses TUMBLE for hourly RSS signal aggregation. Understanding window functions is essential for time-based aggregations in streaming SQL.

