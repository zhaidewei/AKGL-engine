# AWS Lambda for Data Producers

**Learning Point**: 8.1 from knowledge_and_skills_needed_v2.md
**Prerequisites**: AWS Lambda basics, Python basics, Kafka producer knowledge
**Version**: Python 3.9+, AWS Lambda

---

## Definition (Engineering Language)

**AWS Lambda for Data Producers**: Using AWS Lambda functions to fetch data from external sources (RSS feeds, Polymarket API) and produce messages to Kafka topics.

**Lambda Function Structure**: Handler function, dependencies, environment variables, and configuration.

**Lambda Layers**: Shared code and dependencies packaged separately from function code. Used for kafka-python, confluent-kafka libraries.

**Lambda Environment Variables**: Configuration values passed to Lambda function (Kafka endpoints, API keys, etc.).

**Lambda Configuration**: Timeout (5 minutes for MarketLag), memory (256MB for MarketLag), and other settings.

---

## Plain Language Explanation

Think of Lambda like a scheduled worker:

- **Lambda Function** = Worker: "Fetch RSS feeds every 15 minutes"
- **Handler** = Worker's task: "What the worker does when triggered"
- **Layers** = Toolbox: "Shared tools (libraries) the worker uses"
- **Environment Variables** = Instructions: "Kafka endpoint, API keys"

**Why Needed**: MarketLag uses Lambda functions to fetch RSS feeds and Polymarket prices, then send to Kafka.

---

## Analogy

If you know **cron jobs** (which you do), Lambda is similar:
- Cron job = Lambda function (both run on schedule)
- Cron schedule = EventBridge trigger (both trigger at intervals)
- Cron script = Lambda handler (both contain the logic)

Key difference: Lambda is serverless, scales automatically, no server management.

---

## Relationship to Already Learned Topics

- **8.2 EventBridge**: Triggers Lambda functions on schedule
- **8.3 Lambda-Kafka**: Lambda writes to Kafka
- **7.1 RSS Processing**: RSS producer runs in Lambda
- **7.2 Polymarket API**: Polymarket producer runs in Lambda
- **AWS**: You already know AWS Lambda from your experience

---

## Lambda Function Structure: Handler, Dependencies

### Basic Structure

```python
# lambda_function.py
import json
import boto3

def lambda_handler(event, context):
    """
    Lambda handler function.

    Args:
        event: Event data (from EventBridge, API Gateway, etc.)
        context: Lambda context (runtime information)

    Returns:
        dict: Response
    """
    # Your logic here
    result = process_data()

    return {
        'statusCode': 200,
        'body': json.dumps(result)
    }
```

**MarketLag**: RSS and Polymarket producers use this structure.

### Handler Function

**Required**: `lambda_handler(event, context)` is the entry point.

**Event**: Contains trigger data (EventBridge schedule, etc.)

**Context**: Contains runtime information (function name, remaining time, etc.)

---

## Lambda Layers for Shared Dependencies

### Problem

Kafka libraries (kafka-python, confluent-kafka) are large. Including them in function code increases deployment package size.

**Solution**: Use Lambda Layers for shared dependencies.

### Creating Layer

```bash
# Create layer directory
mkdir python
pip install kafka-python confluent-kafka -t python/

# Package layer
zip -r kafka-layer.zip python/

# Upload to Lambda (via AWS CLI or console)
aws lambda publish-layer-version \
    --layer-name kafka-dependencies \
    --zip-file fileb://kafka-layer.zip \
    --compatible-runtimes python3.9
```

### Using Layer

Attach layer to Lambda function (via console or CLI):

```python
# In Lambda function, libraries are available
from kafka import KafkaProducer
from confluent_kafka import Producer
```

**MarketLag**: Uses Lambda layers for Kafka dependencies.

---

## Lambda Environment Variables and Configuration

### Environment Variables

Set in Lambda configuration:

```python
import os

# Access environment variables
kafka_endpoint = os.environ['KAFKA_ENDPOINT']
api_key = os.environ['API_KEY']
api_secret = os.environ['API_SECRET']
```

**MarketLag**: Uses environment variables for:
- Confluent Cloud Kafka endpoint
- API keys and secrets
- DynamoDB table names

### Configuration

**Timeout**: 5 minutes (300 seconds) for MarketLag
- RSS producer: May need time to fetch and process feeds
- Polymarket producer: May need time for API calls

**Memory**: 256MB for MarketLag
- Sufficient for RSS parsing and Kafka publishing
- Can increase if needed

**MarketLag Configuration**:
- Timeout: 300 seconds (5 minutes)
- Memory: 256 MB
- Runtime: Python 3.9+

---

## Lambda Timeout and Memory Configuration: 5 Minutes Timeout, 256MB Memory

### Timeout Configuration

**Setting**: 300 seconds (5 minutes)

**Why**:
- RSS fetching and parsing may take time
- Polymarket API calls may have delays
- Kafka publishing may take time

**MarketLag**: Uses 5-minute timeout for both producers.

### Memory Configuration

**Setting**: 256 MB

**Why**:
- RSS parsing is lightweight
- Kafka publishing is lightweight
- 256 MB is sufficient

**MarketLag**: Uses 256 MB for both producers.

### Configuration Example

```python
# Lambda configuration (via AWS Console or CLI)
# Timeout: 300 seconds
# Memory: 256 MB
# Runtime: Python 3.9
# Handler: lambda_function.lambda_handler
```

---

## Minimum Viable Code

```python
# lambda_function.py
import os
import json
from datetime import datetime
import pytz
from kafka import KafkaProducer

# Environment variables
KAFKA_ENDPOINT = os.environ['KAFKA_ENDPOINT']
KAFKA_API_KEY = os.environ['KAFKA_API_KEY']
KAFKA_API_SECRET = os.environ['KAFKA_API_SECRET']
TOPIC = os.environ['KAFKA_TOPIC']

def lambda_handler(event, context):
    """
    Lambda handler for data producer.
    """
    try:
        # Create Kafka producer
        producer = KafkaProducer(
            bootstrap_servers=KAFKA_ENDPOINT,
            security_protocol='SASL_SSL',
            sasl_mechanism='PLAIN',
            sasl_plain_username=KAFKA_API_KEY,
            sasl_plain_password=KAFKA_API_SECRET,
            value_serializer=lambda v: json.dumps(v).encode('utf-8')
        )

        # Fetch data (RSS or Polymarket)
        data = fetch_data()  # Your data fetching logic

        # Send to Kafka
        for item in data:
            producer.send(TOPIC, value=item)

        producer.flush()
        producer.close()

        return {
            'statusCode': 200,
            'body': json.dumps({'message': 'Success', 'count': len(data)})
        }
    except Exception as e:
        print(f"Error: {e}")
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)})
        }

def fetch_data():
    """
    Fetch data from source (RSS or Polymarket).
    """
    # Your data fetching logic
    return []
```

---

## Common Mistakes

1. **Timeout too short**:
   - ❌ 30 seconds timeout (may timeout on slow API calls)
   - ✅ Use 5 minutes (300 seconds) for MarketLag

2. **Not using layers**:
   - ❌ Including large libraries in function code (slow deployments)
   - ✅ Use Lambda layers for shared dependencies

3. **Not handling errors**:
   - ❌ No error handling, Lambda fails silently
   - ✅ Implement try-catch, return error status

4. **Not closing Kafka producer**:
   - ❌ Producer not closed, connections leak
   - ✅ Always call `producer.close()` or use context manager

5. **Hardcoding configuration**:
   - ❌ Hardcoding Kafka endpoints, API keys
   - ✅ Use environment variables for configuration

---

## Mind Trigger: When to Think About This

Think about AWS Lambda for data producers when:
- **Implementing data producers**: MarketLag uses Lambda for RSS and Polymarket producers
- **Scheduling tasks**: Section 8.2 covers EventBridge scheduling
- **Kafka integration**: Section 8.3 covers Lambda-Kafka integration
- **Error handling**: Section 9.1 covers error handling patterns
- **Configuration**: Setting timeout, memory, environment variables

**In MarketLag project**: RSS and Polymarket producers run as Lambda functions. Use 5-minute timeout, 256MB memory, Lambda layers for dependencies. Understanding Lambda is essential for data producer implementation.

---

## Summary

AWS Lambda functions are used for data producers in MarketLag. Lambda structure includes handler function, dependencies (via layers), environment variables, and configuration (timeout, memory). MarketLag uses 5-minute timeout and 256MB memory. Lambda layers are used for shared dependencies (Kafka libraries). Understanding Lambda is essential for data producer implementation.

