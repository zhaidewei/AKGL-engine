# Computation Placement: Producer vs Flink

**Learning Point**: 7.3 from knowledge_and_skills_needed_v2.md
**Prerequisites**: 7.4 (Price Delta Calculation), understanding of distributed systems architecture
**Version**: Flink 2.2.0

---

## Definition (Engineering Language)

**Computation Placement**: Architectural decision of where to perform computation logic - in the data producer (before Kafka) or in Flink (after Kafka).

**Producer-Side Computation**: Performing computation in the producer (e.g., Lambda function) before writing to Kafka. Requires external state storage (DynamoDB, S3).

**Flink-Side Computation**: Performing computation in Flink operators using Flink state management. All logic centralized in Flink.

**Trade-offs**: Each approach has pros and cons regarding complexity, state management, and system design.

---

## Plain Language Explanation

Think of computation placement like choosing where to cook:

- **Producer-Side** = Cook before delivery: "Calculate price_delta in Lambda, then send to Kafka"
- **Flink-Side** = Cook after delivery: "Send raw prices to Kafka, calculate delta in Flink"

**Why It Matters**: MarketLag chose producer-side for price_delta to simplify Flink jobs, but this requires DynamoDB for state.

---

## Analogy

If you know **ETL vs ELT** (which you do), computation placement is similar:
- ETL (Extract-Transform-Load) = Producer-side (transform before loading)
- ELT (Extract-Load-Transform) = Flink-side (load first, transform later)

Key difference: In streaming, "load" is Kafka, and we choose where to "transform".

---

## Relationship to Already Learned Topics

- **7.4 Price Delta**: MarketLag calculates price_delta in producer
- **8.1 AWS Lambda**: Producer-side computation runs in Lambda
- **1.7 State Types**: Flink-side computation uses Flink state
- **Architecture**: You already know architectural trade-offs

---

## Decision Factor: Where to Place Computation Logic

### Key Considerations

1. **State Management**: Where to store previous values?
2. **Complexity**: Which system handles complexity better?
3. **Scalability**: Which approach scales better?
4. **Maintainability**: Which is easier to maintain?

**MarketLag Decision**: Producer-side for price_delta (simpler Flink, requires DynamoDB).

---

## Producer-Side Computation: price_delta Calculation in Lambda

### Architecture

```
Lambda → DynamoDB (prev_price) → Calculate delta → Kafka (with price_delta)
```

### Pros

1. **Reduces Flink State Complexity**: Flink doesn't need to store previous prices
2. **Simpler Flink Job**: Flink just processes pre-calculated deltas
3. **Separation of Concerns**: Lambda handles data preparation, Flink handles processing
4. **Easier Testing**: Can test Lambda and Flink independently

**MarketLag**: Uses this approach for price_delta calculation.

### Cons

1. **Requires External State Storage**: Need DynamoDB (or S3) for previous prices
2. **Additional Infrastructure**: More components to manage
3. **Potential Inconsistency**: Lambda and Flink may have different views
4. **Cost**: DynamoDB storage and read/write costs

**MarketLag**: Accepts these trade-offs for simpler Flink logic.

---

## Flink-Side Computation: Computation in Flink Operators

### Architecture

```
Lambda → Kafka (raw prices) → Flink (calculate delta using state) → Output
```

### Pros

1. **Centralized Logic**: All computation in one place (Flink)
2. **Flink State Management**: Uses Flink's built-in state management
3. **Consistency**: Single source of truth (Flink state)
4. **No External Dependencies**: No need for DynamoDB

### Cons

1. **More Complex Flink State**: Need to manage state in Flink
2. **Larger State Size**: Flink state grows with number of markets
3. **Flink Complexity**: More complex Flink job logic
4. **State Management Overhead**: Flink state management complexity

**MarketLag**: Did not choose this approach (chose producer-side instead).

---

## Project Choice: price_delta Calculated in Producer (Lambda) Using DynamoDB

### MarketLag Architecture

**Decision**: Calculate price_delta in Lambda producer, not in Flink.

**Implementation**:
1. Lambda fetches current price from Polymarket API
2. Lambda reads previous price from DynamoDB
3. Lambda calculates: `price_delta = current_price - prev_price`
4. Lambda writes to Kafka: `{price, price_delta, ...}`
5. Lambda updates DynamoDB with current price

**Why This Choice**:
- **Simpler Flink**: Flink job doesn't need to manage price history state
- **Separation**: Lambda handles data preparation, Flink handles lag detection
- **Scalability**: DynamoDB handles state scaling automatically

---

## Minimum Viable Code

```python
# Producer-side computation (Lambda)
import boto3
from decimal import Decimal

dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('polymarket_previous_prices')

def calculate_price_delta(market_slug, outcome, current_price):
    """
    Calculate price delta using DynamoDB for previous price.

    Args:
        market_slug: Market slug
        outcome: "YES" or "NO"
        current_price: Current price from API

    Returns:
        float: Price delta
    """
    key = f"{market_slug}|{outcome}"

    # Read previous price from DynamoDB
    response = table.get_item(Key={'key': key})
    prev_price = response.get('Item', {}).get('price', None)

    # Calculate delta
    if prev_price is None:
        price_delta = 0.0  # First time, no previous price
    else:
        price_delta = float(current_price) - float(prev_price)

    # Update DynamoDB with current price
    table.put_item(Item={
        'key': key,
        'price': Decimal(str(current_price)),
        'updated_at': datetime.now(pytz.UTC).isoformat()
    })

    return price_delta

# Usage in Lambda
current_price = get_price_from_api()
price_delta = calculate_price_delta(market_slug, outcome, current_price)

# Send to Kafka with price_delta
send_to_kafka({
    'market_slug': market_slug,
    'price': current_price,
    'price_delta': price_delta,
    'event_time': datetime.now(pytz.UTC).isoformat()
})
```

---

## Common Mistakes

1. **Not understanding trade-offs**:
   - ❌ Choosing approach without understanding pros/cons
   - ✅ Understand both approaches, choose based on requirements

2. **Mixing approaches inconsistently**:
   - ❌ Some computation in producer, some in Flink (confusing)
   - ✅ Be consistent: choose one approach per computation type

3. **Not considering state size**:
   - ❌ Using Flink state for very large state (expensive)
   - ✅ Consider external storage (DynamoDB) for large state

4. **Not handling first-time case**:
   - ❌ No previous price, calculation fails
   - ✅ Handle first-time: delta = 0 or skip calculation

5. **Not updating state**:
   - ❌ Calculate delta but forget to update previous price
   - ✅ Always update state after calculation

---

## Mind Trigger: When to Think About This

Think about computation placement when:
- **Designing architecture**: MarketLag chose producer-side for price_delta
- **Deciding where to compute**: Producer vs Flink decision
- **Managing state**: Understanding state management trade-offs
- **Simplifying Flink jobs**: Producer-side can simplify Flink logic
- **Scaling considerations**: Understanding scalability implications

**In MarketLag project**: Calculates price_delta in Lambda producer using DynamoDB for previous prices. This simplifies Flink jobs but requires DynamoDB infrastructure. Understanding computation placement helps make architectural decisions.

---

## Summary

Computation placement is an architectural decision: producer-side (before Kafka) or Flink-side (after Kafka). Producer-side reduces Flink complexity but requires external state storage. Flink-side centralizes logic but increases Flink state complexity. MarketLag chose producer-side for price_delta calculation. Understanding trade-offs helps make the right architectural decisions.

