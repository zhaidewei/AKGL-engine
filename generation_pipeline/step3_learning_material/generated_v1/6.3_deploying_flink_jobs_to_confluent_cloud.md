# Deploying Flink Jobs to Confluent Cloud

**Learning Point**: 6.3 from knowledge_and_skills_needed_v2.md
**Prerequisites**: 6.1 (Confluent Cloud Overview), 6.2 (Flink Environment), understanding of deployment
**Version**: Flink 2.2.0

---

## Definition (Engineering Language)

**Job Submission Methods**: Ways to deploy Flink jobs to Confluent Cloud: UI (web interface), CLI (command line), and API (REST API).

**Job Configuration**: Settings for Flink jobs: parallelism, checkpoint interval, checkpoint mode, etc.

**Job Monitoring**: Observing job health and performance through UI dashboard, metrics, and logs.

**Job Update**: Updating deployed jobs: versioning, rolling updates, configuration changes.

**Confluent Cloud UI**: Web interface for managing Flink environments and jobs.

**Confluent CLI**: Command-line tool for managing Confluent Cloud resources.

**Confluent REST API**: Programmatic interface for managing Confluent Cloud resources.

---

## Plain Language Explanation

Think of deploying Flink jobs like deploying applications:

- **UI** = Web dashboard: Click buttons to deploy jobs
- **CLI** = Command line: Type commands to deploy jobs
- **API** = Programmatic: Write scripts to deploy jobs

**Why Needed**: MarketLag jobs need to be deployed to Confluent Cloud for production. Understanding deployment methods helps choose the right approach.

---

## Analogy

If you know **AWS Lambda deployment** (which you do), Confluent Cloud deployment is similar:
- AWS Console = Confluent Cloud UI (both web interfaces)
- AWS CLI = Confluent CLI (both command-line tools)
- AWS API = Confluent REST API (both programmatic interfaces)

Key difference: Confluent Cloud manages Flink infrastructure, you just deploy jobs.

---

## Relationship to Already Learned Topics

- **6.1 Confluent Cloud Overview**: Understanding Confluent Cloud architecture
- **6.2 Flink Environment**: Flink environment must be created before deploying jobs
- **1.10 Checkpoints**: Checkpoint configuration is part of job deployment
- **Deployment**: You already know deployment patterns from AWS experience

---

## Pseudocode (From Confluent Cloud)

Based on Confluent Cloud deployment process:

```bash
# CLI deployment (simplified)
confluent flink job create \
    --name "marketlag-job-1" \
    --sql-file "job1.sql" \
    --parallelism 2 \
    --checkpoint-interval 300000
```

---

## Source Code References

**Confluent Cloud Documentation**: Confluent Cloud UI, CLI, and API documentation (not in Flink source).

**MarketLag Project**: Deployment configuration in project design.

---

## Job Submission Methods

### UI: Upload JAR or SQL Script

**Steps**:
1. Log in to Confluent Cloud UI
2. Navigate to Flink environment
3. Click "Create Job"
4. Upload SQL script or JAR file
5. Configure job settings (parallelism, checkpoint interval)
6. Submit job

**Use Case**: One-off deployments, manual deployments, testing.

**MarketLag Project**: Can use UI for initial deployment and testing.

### CLI: Using `confluent flink job create` Command

**Installation**:
```bash
# Install Confluent CLI
curl -sL --http1.1 https://cnfl.io/cli | sh -s -- -b /usr/local/bin
```

**Authentication**:
```bash
confluent login
```

**Create Job**:
```bash
confluent flink job create \
    --name "marketlag-job-1" \
    --sql-file "job1.sql" \
    --parallelism 2 \
    --checkpoint-interval 300000 \
    --checkpoint-mode EXACTLY_ONCE
```

**Use Case**: Automated deployments, CI/CD pipelines, scripting.

**MarketLag Project**: Can use CLI for automated deployments.

### API: REST API for Programmatic Deployment

**Example**:
```bash
curl -X POST "https://api.confluent.cloud/flink/v1/environments/{env-id}/jobs" \
    -H "Authorization: Basic <credentials>" \
    -H "Content-Type: application/json" \
    -d '{
        "name": "marketlag-job-1",
        "sql": "...",
        "parallelism": 2,
        "checkpoint_interval": 300000
    }'
```

**Use Case**: Custom deployment tools, integration with other systems.

**MarketLag Project**: Can use API for custom deployment automation.

---

## Job Configuration

### Parallelism: 2 (for MVP)

```bash
--parallelism 2
```

**MarketLag Project**: Uses parallelism=2 to match 2 CFU allocation.

**Why**: 2 CFU provides 2 parallel subtasks. Setting parallelism=2 ensures optimal resource usage.

### Checkpoint Interval: 300000 (5 minutes)

```bash
--checkpoint-interval 300000
```

**MarketLag Project**: Uses 5-minute checkpoint interval (300,000 milliseconds).

**Why**: Balance between recovery time and checkpoint overhead.

### Checkpoint Mode: EXACTLY_ONCE

```bash
--checkpoint-mode EXACTLY_ONCE
```

**MarketLag Project**: Uses EXACTLY_ONCE for correctness.

**Why**: Ensures each record is processed exactly once, even after failures.

---

## Job Monitoring: UI Dashboard, Metrics, Logs

### UI Dashboard

Confluent Cloud UI provides:
- **Job Status**: Running, stopped, failed
- **Metrics**: Throughput, latency, checkpoint success rate
- **Logs**: Job execution logs
- **Graph**: Job graph visualization

**Use Case**: Real-time monitoring, debugging, troubleshooting.

### Metrics

Key metrics to monitor:
- **Throughput**: Records processed per second
- **Latency**: End-to-end latency
- **Checkpoint Success Rate**: Percentage of successful checkpoints
- **Consumer Lag**: Kafka consumer lag

**MarketLag Project**: Monitor these metrics for all three jobs.

### Logs

Access logs through:
- **UI**: View logs in Confluent Cloud UI
- **CLI**: `confluent flink job logs <job-id>`
- **API**: REST API endpoint for logs

**Use Case**: Debugging, troubleshooting, audit trail.

---

## Job Update: Versioning, Rolling Updates

### Versioning

Confluent Cloud supports job versioning:
- **Version History**: Track job versions
- **Rollback**: Roll back to previous version
- **Comparison**: Compare versions

**Use Case**: Safe deployments, rollback on issues.

### Rolling Updates

Confluent Cloud performs rolling updates:
- **Zero Downtime**: Updates without stopping job
- **Gradual Rollout**: Updates subtasks gradually
- **Automatic Rollback**: Roll back on errors

**Use Case**: Production updates without downtime.

---

## Minimum Viable Code

### SQL Job File (job1.sql)

```sql
-- MarketLag Job 1: RSS Signal Aggregation
CREATE TABLE rss_events (
    -- schema
) WITH (
    'connector' = 'kafka',
    -- configuration
);

CREATE TABLE rss_signals_hourly (
    -- schema
) WITH (
    'connector' = 'kafka',
    -- configuration
);

INSERT INTO rss_signals_hourly
SELECT
    market_slug,
    TUMBLE_START(published_at, INTERVAL '1' HOUR) as window_start,
    COUNT(*) as mention_count,
    SUM(keyword_score) as keyword_score,
    AVG(article_score * source_weight) as source_weighted_signal
FROM rss_events
GROUP BY market_slug, TUMBLE(published_at, INTERVAL '1' HOUR);
```

### CLI Deployment

```bash
confluent flink job create \
    --name "marketlag-job-1" \
    --sql-file "job1.sql" \
    --parallelism 2 \
    --checkpoint-interval 300000 \
    --checkpoint-mode EXACTLY_ONCE
```

---

## Common Mistakes

1. **Wrong parallelism**:
   - ❌ Setting parallelism higher than CFU allocation
   - ✅ Match parallelism to CFU (2 CFU = parallelism 2)

2. **Missing checkpoint configuration**:
   - ❌ Not configuring checkpoint interval
   - ✅ Always configure: checkpoint-interval, checkpoint-mode

3. **Wrong SQL file**:
   - ❌ Deploying wrong SQL file
   - ✅ Verify SQL file before deployment

4. **Not monitoring after deployment**:
   - ❌ Deploying and forgetting
   - ✅ Monitor metrics and logs after deployment

5. **Not testing locally**:
   - ❌ Deploying without local testing
   - ✅ Test locally first (section 10.1)

---

## Mind Trigger: When to Think About This

Think about deploying Flink jobs when:
- **Deploying to production**: MarketLag jobs need to be deployed to Confluent Cloud
- **Choosing deployment method**: UI, CLI, or API based on use case
- **Configuring jobs**: Set parallelism, checkpoint interval, checkpoint mode
- **Monitoring jobs**: Section 6.4 covers monitoring in detail
- **Updating jobs**: Understanding versioning and rolling updates

**In MarketLag project**: All three jobs are deployed to Confluent Cloud. Use parallelism=2, checkpoint-interval=300000, checkpoint-mode=EXACTLY_ONCE. Monitor jobs through UI dashboard and metrics.

---

## Summary

Flink jobs can be deployed to Confluent Cloud via UI (web interface), CLI (command line), or API (REST API). Job configuration includes parallelism (2 for MVP), checkpoint interval (300000 = 5 minutes), and checkpoint mode (EXACTLY_ONCE). Jobs are monitored through UI dashboard, metrics, and logs. Updates support versioning and rolling updates. MarketLag uses these deployment methods for all three jobs. Understanding deployment is essential for production operations.

