# Flink Architecture and Execution Model

**Learning Point**: 1.1 from knowledge_and_skills_needed_v2.md
**Prerequisites**: 理解分布式系统、Kafka 基础知识（您已经从经验中了解这些）
**Version**: Flink 2.2.0

---

## Definition (Engineering Language)

**Flink Cluster Architecture**: 由 JobManager（协调器）和一个或多个 TaskManager（工作节点）组成的分布式系统。JobManager 管理作业生命周期、调度和 checkpoint 协调。TaskManager 在并行 slot 中执行任务，每个 slot 可以运行一个算子的一个并行实例。

**Execution Model**: Flink 使用数据流图模型，其中算子在有向无环图（DAG）中连接。图被划分为并行子任务，每个子任务在 TaskManager 的 slot 中运行。数据通过算子之间的数据流在图中流动。

---

## Plain Language Explanation

将 Flink 想象成一个餐厅厨房：

- **JobManager** = 主厨：协调整个操作，决定任务分配到何处，监控进度，并处理紧急情况（故障）
- **TaskManager** = 厨房工作站：多个工作站（slots），实际烹饪（数据处理）发生的地方
- **Slots** = 单个烹饪台：每个可以同时处理一道菜（一个并行任务）
- **Job** = 完整的食谱：从源到汇的整个数据处理管道

当您提交作业时，JobManager 将其分解为任务并分配给 TaskManager 上的可用 slot。如果 TaskManager 失败，JobManager 会将其任务重新分配给其他 TaskManager。

---

## Analogy

如果您熟悉 **Apache Spark**（您知道），Flink 类似但针对流处理进行了优化：
- Spark 的 Driver = Flink 的 JobManager
- Spark 的 Executors = Flink 的 TaskManagers
- Spark 的 Cores = Flink 的 Slots

关键区别：Spark 以批处理方式处理数据（流处理中是微批），而 Flink 以真正的流处理方式逐条处理记录。

---

## Relationship to Already Learned Topics

- **Kafka**: Flink 从 Kafka topic 读取数据（您从经验中了解 Kafka）。Kafka 分区映射到 Flink 并行度 - 每个 Kafka 分区可以由一个 Flink 子任务处理。
- **Distributed Systems**: 类似于您使用 Spark 集群的经验 - JobManager 像 Spark Driver 一样协调，TaskManager 像 Spark Executor 一样执行。
- **Event-Driven Architecture**: Flink 是事件驱动的 - 每条记录立即触发处理，不像批处理系统那样等待数据累积。

---

## Pseudocode (From Source Code)

基于 Flink 2.2.0 源代码结构：

```java
// JobManager (simplified)
class JobManager {
    JobGraph jobGraph;  // The dataflow graph
    List<TaskManager> taskManagers;  // Available workers

    void submitJob(JobGraph graph) {
        // 1. Parse job graph into execution graph
        ExecutionGraph execGraph = createExecutionGraph(graph);

        // 2. Schedule tasks to TaskManagers
        for (ExecutionVertex vertex : execGraph.getVertices()) {
            TaskManager tm = selectTaskManager();
            Slot slot = tm.allocateSlot();
            scheduleTask(vertex, slot);
        }

        // 3. Deploy tasks
        deployTasks();
    }
}

// TaskManager (simplified)
class TaskManager {
    List<Slot> slots;  // Available processing slots
    Map<ExecutionAttemptID, Task> runningTasks;

    void deployTask(TaskDeploymentDescriptor descriptor) {
        Slot slot = allocateSlot();
        Task task = createTask(descriptor);
        slot.setTask(task);
        task.start();
    }
}
```

---

## Source Code References

**Local Path**: `generation_pipeline/step0_context/source_codes/flink/flink-runtime/src/main/java/org/apache/flink/runtime/jobmaster/JobManagerRunner.java`

**GitHub URL**: https://github.com/apache/flink/blob/release-2.2/flink-runtime/src/main/java/org/apache/flink/runtime/jobmaster/JobManagerRunner.java

**Key Classes**:
- `JobManagerRunner`: JobManager 的主入口点
- `TaskManagerRunner`: TaskManager 的主入口点
- `ExecutionGraph`: 表示执行计划

---

## Execution Environments

Flink 提供三种执行环境（来自项目设计 v5）：

1. **LocalEnvironment**: 在单个 JVM 中运行 Flink（用于测试）
   ```java
   StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
   // Automatically detects local mode
   ```

2. **RemoteEnvironment**: 连接到远程 Flink 集群
   ```java
   StreamExecutionEnvironment env = StreamExecutionEnvironment.createRemoteEnvironment(
       "jobmanager-host", 1234
   );
   ```

3. **Confluent Cloud Environment**: 托管的 Flink（在 MarketLag 项目中使用）
   - 无需更改代码 - 只需将 JAR/SQL 部署到 Confluent Cloud
   - 环境已预配置 RocksDB state backend

---

## Minimum Viable Code

```java
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.datastream.DataStream;

public class FlinkArchitectureDemo {
    public static void main(String[] args) throws Exception {
        // Creates execution environment (auto-detects local vs cluster)
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // Set parallelism (number of parallel subtasks per operator)
        env.setParallelism(2);  // Each operator will have 2 parallel instances

        // Create a simple data stream
        DataStream<String> stream = env.fromElements("Hello", "Flink", "World");

        // Transform data (creates operator in the DAG)
        DataStream<String> upper = stream.map(s -> s.toUpperCase());

        // Print (sink operator)
        upper.print();

        // Execute the job
        // JobManager will:
        // 1. Create execution graph
        // 2. Schedule tasks to TaskManager slots
        // 3. Deploy and run
        env.execute("Flink Architecture Demo");
    }
}
```

**本地运行**:
```bash
# Compile (assuming Maven project)
mvn clean package

# Run
java -cp target/your-jar.jar FlinkArchitectureDemo
```

---

## Parallelism and Task Distribution

**Parallelism** = 算子的并行实例数量

示例：
- 并行度为 4 的 Source 算子 → 4 个子任务，每个从不同的 Kafka 分区读取
- 并行度为 4 的 Map 算子 → 4 个并行处理的子任务
- 并行度为 2 的 Sink 算子 → 2 个并行写入的子任务

**Task Distribution**:
- JobManager 尝试在 TaskManager 之间均匀分配任务
- 如果您有 4 个 TaskManager，每个有 2 个 slot = 总共 8 个 slot
- 并行度为 8 的作业将使用所有 slot
- 并行度为 4 的作业将使用 4 个 slot（理想情况下每个 TaskManager 一个）

---

## Common Mistakes

1. **混淆并行度与 Kafka 分区**:
   - ❌ 将并行度设置得高于 Kafka 分区数（浪费资源）
   - ✅ 将并行度与 Kafka 分区数匹配以获得最佳吞吐量

2. **不理解 slot 共享**:
   - ❌ 认为每个算子都需要自己的 slot
   - ✅ 多个算子可以共享一个 slot（算子链）

3. **忽略 TaskManager 资源**:
   - ❌ 不监控 TaskManager 内存/CPU
   - ✅ 监控 TaskManager 指标以避免 OOM

4. **混淆本地与集群环境**:
   - ❌ 在生产环境中使用 LocalEnvironment
   - ✅ 生产环境使用 RemoteEnvironment 或 Confluent Cloud

---

## Mind Trigger: When to Think About This

在以下情况下考虑 Flink 架构：
- **部署作业**: 理解 JobManager 如何调度任务有助于调试部署问题
- **性能调优**: 了解 slot 分布有助于优化并行度设置
- **故障排查**: JobManager 日志显示调度决策；TaskManager 日志显示执行问题
- **扩展**: 添加 TaskManager 会增加可用 slot，允许更高的并行度
- **资源规划**: 每个 slot 消耗内存/CPU - 相应地规划 TaskManager 资源

**在 MarketLag 项目中**: Confluent Cloud 自动管理 JobManager 和 TaskManager，但您仍需要设置 parallelism=2（根据项目设计）以匹配您的 2 CFU 分配。

---

## Summary

Flink 的架构将协调（JobManager）与执行（TaskManager）分离。作业被分解为分布在 slot 上的并行任务。理解这一点有助于部署、性能调优和故障排查。MarketLag 项目使用 Confluent Cloud 的托管 Flink，它处理基础设施，但您仍需要配置并行度并监控执行。

