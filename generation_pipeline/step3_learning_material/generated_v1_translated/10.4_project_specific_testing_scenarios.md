# Project-Specific Testing Scenarios

**Learning Point**: 10.4 from knowledge_and_skills_needed_v2.md
**Prerequisites**: 10.1 (Local Testing), 10.2 (Integration Testing), 12.1 (Lag Detection)
**Version**: Flink 2.2.0

---

## Definition (Engineering Language)

**Project-Specific Testing Scenarios**: Test cases tailored to MarketLag project's specific functionality and business logic.

**Testing Window Aggregation (Job 1)**: Verifying that Job 1 correctly calculates mention_count, keyword_score, and source_weighted_signal over hourly windows.

**Testing Join Correctness (Job 3)**: Verifying that equi-join correctly matches window_start with event_time.

**Testing State Recovery**: Verifying that max_signal_delta state is correctly restored after failure.

**Testing Watermark Behavior**: Verifying late data handling and window triggering with watermarks.

**Testing Lag Detection Logic**: Verifying that signal_delta > 1.0 AND abs(price_delta) < 0.02 correctly flags lag.

---

## Plain Language Explanation

将项目特定的测试想象成测试自定义功能：

- **Window Aggregation Test** = 测试 Job 1："它是否正确计算信号？"
- **Join Test** = 测试 Job 3："它是否正确连接信号和价格？"
- **Lag Detection Test** = 测试核心逻辑："它是否正确检测 lag？"

**Why Needed**: MarketLag 有需要针对性测试的特定业务逻辑。

---

## Analogy

如果您了解 **functional testing**（您了解），项目特定的测试是类似的：
- Functional tests = Project-specific tests（两者都测试业务逻辑）
- Test cases = Specific scenarios（两者都测试特定功能）

关键区别：项目特定的测试是针对 MarketLag 独特逻辑定制的。

---

## Relationship to Already Learned Topics

- **10.1 Local Testing**: Use local testing for project-specific scenarios
- **12.1 Lag Detection**: Tests lag detection algorithm
- **3.1 Window Functions**: Tests window aggregation
- **3.3 Equi-Join**: Tests join correctness

---

## Testing Window Aggregation (Job 1)

### Test Scenario

**Goal**: Verify Job 1 correctly aggregates RSS events into hourly signals.

**Test Data**:
- Market: "fed-hike-january"
- Window: 14:00-15:00 UTC
- Events:
  - Reuters article, score=7.5, weight=1.0
  - Bloomberg article, score=5.0, weight=0.9
  - Others article, score=3.0, weight=0.7

**Expected Results**:
- mention_count = 3
- keyword_score = 15.5 (7.5 + 5.0 + 3.0)
- source_weighted_signal = 5.4 (AVG(7.5×1.0, 5.0×0.9, 3.0×0.7))

### Implementation

```java
@Test
public void testWindowAggregation() throws Exception {
    StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment();
    env.setParallelism(1);

    // Create test RSS events
    DataStream<RSSEvent> events = env.fromElements(
        new RSSEvent("fed-hike-january", 7.5, 1.0, "Reuters", 1400000L),
        new RSSEvent("fed-hike-january", 5.0, 0.9, "Bloomberg", 1401000L),
        new RSSEvent("fed-hike-january", 3.0, 0.7, "Others", 1402000L)
    );

    // Assign timestamps and watermarks
    DataStream<RSSEvent> withTimestamps = events.assignTimestampsAndWatermarks(...);

    // Window aggregation (Job 1 logic)
    DataStream<Signal> signals = withTimestamps
        .keyBy(RSSEvent::getMarketSlug)
        .window(TumblingEventTimeWindows.of(Time.hours(1)))
        .aggregate(new SignalAggregateFunction());

    // Collect and verify
    List<Signal> results = collectResults(signals);

    assertEquals(1, results.size());
    Signal signal = results.get(0);
    assertEquals(3, signal.getMentionCount());
    assertEquals(15.5, signal.getKeywordScore(), 0.01);
    assertEquals(5.4, signal.getSourceWeightedSignal(), 0.01);
}
```

**MarketLag**: Tests Job 1 window aggregation with known test data.

---

## Testing Join Correctness (Job 3)

### Test Scenario

**Goal**: Verify Job 3 correctly joins RSS signals with Polymarket prices.

**Test Data**:
- RSS Signal: market="fed-hike-january", window_start=14:00, signal=5.4
- Price: market="fed-hike-january", event_time=14:00, price=0.65, price_delta=0.01

**Expected**: Records should join on market_slug and window_start = event_time.

### Implementation

```java
@Test
public void testJoinCorrectness() throws Exception {
    StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment();
    env.setParallelism(1);

    // Create test RSS signals
    DataStream<Signal> signals = env.fromElements(
        new Signal("fed-hike-january", 14_00_00L, 5.4)
    );

    // Create test prices
    DataStream<Price> prices = env.fromElements(
        new Price("fed-hike-january", 14_00_00L, 0.65, 0.01)
    );

    // Join (Job 3 logic)
    DataStream<Joined> joined = signals.join(prices)
        .where(s -> s.getMarketSlug() + "|" + s.getWindowStart())
        .equalTo(p -> p.getMarketSlug() + "|" + p.getEventTime())
        .window(TumblingEventTimeWindows.of(Time.hours(1)))
        .apply(new JoinFunction<Signal, Price, Joined>() {
            @Override
            public Joined join(Signal s, Price p) {
                return new Joined(s, p);
            }
        });

    // Verify join
    List<Joined> results = collectResults(joined);
    assertEquals(1, results.size());
    Joined result = results.get(0);
    assertEquals("fed-hike-january", result.getMarketSlug());
    assertEquals(5.4, result.getRssSignal(), 0.01);
    assertEquals(0.65, result.getPrice(), 0.01);
}
```

**MarketLag**: Tests Job 3 equi-join with aligned timestamps.

---

## Testing State Recovery: Verify max_signal_delta State Restoration

### Test Scenario

**Goal**: Verify that max_signal_delta state is correctly restored after failure.

**Test Steps**:
1. Process events, update max_signal_delta state
2. Create checkpoint
3. Simulate failure
4. Restore from checkpoint
5. Verify state is correct

### Implementation

```java
@Test
public void testStateRecovery() throws Exception {
    // First run: create state and checkpoint
    StreamExecutionEnvironment env1 = StreamExecutionEnvironment.createLocalEnvironment();
    env1.enableCheckpointing(1000);

    DataStream<Event> events1 = env1.fromElements(
        new Event("market1", "YES", 2.0),  // signal_delta = 2.0
        new Event("market1", "YES", 3.0)  // signal_delta = 3.0 (new max)
    );

    events1.keyBy(e -> e.getMarket() + "|" + e.getOutcome())
        .process(new ConfidenceCalculator())  // Updates max_signal_delta
        .print();

    env1.execute("State Creation");

    // Second run: restore and verify
    StreamExecutionEnvironment env2 = StreamExecutionEnvironment.createLocalEnvironment();
    env2.enableCheckpointing(1000);
    // Restore from checkpoint

    // Process new event
    DataStream<Event> events2 = env2.fromElements(
        new Event("market1", "YES", 1.5)  // signal_delta = 1.5 < max (3.0)
    );

    // Verify max_signal_delta is 3.0 (from checkpoint)
    // Verify confidence calculation uses max = 3.0
}
```

**MarketLag**: Tests that max_signal_delta state is correctly restored.

---

## Testing Watermark Behavior: Late Data Handling, Window Triggering

### Test Scenario

**Goal**: Verify watermarks trigger windows correctly and handle late data.

**Test Data**:
- Event 1: timestamp=14:00, watermark=13:55
- Event 2: timestamp=14:30, watermark=14:25
- Event 3: timestamp=14:45, watermark=14:40
- Late Event: timestamp=13:50 (arrives after watermark=14:40)

**Expected**: Window [14:00, 15:00) triggers when watermark >= 15:00. Late event handled according to allowed lateness.

### Implementation

```java
@Test
public void testWatermarkBehavior() throws Exception {
    StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment();
    env.setParallelism(1);

    // Create events with timestamps
    DataStream<Event> events = env.fromElements(
        new Event(14_00_00L),
        new Event(14_30_00L),
        new Event(14_45_00L),
        new Event(13_50_00L)  // Late event
    );

    // Assign watermarks (5-minute delay)
    DataStream<Event> withWatermarks = events.assignTimestampsAndWatermarks(
        WatermarkStrategy
            .<Event>forBoundedOutOfOrderness(Duration.ofMinutes(5))
            .withTimestampAssigner((e, ts) -> e.getTimestamp())
    );

    // Window aggregation
    DataStream<Result> windowed = withWatermarks
        .keyBy(Event::getKey)
        .window(TumblingEventTimeWindows.of(Time.hours(1)))
        .allowedLateness(Time.minutes(10))  // Allow 10 minutes lateness
        .aggregate(new AggregateFunction());

    // Verify windows trigger correctly
    // Verify late event is handled
}
```

**MarketLag**: Tests watermark behavior with 5-minute delay.

---

## Testing Lag Detection Logic: signal_delta > 1.0 AND abs(price_delta) < 0.02

### Test Scenario

**Goal**: Verify lag detection algorithm correctly flags lag conditions.

**Test Cases**:
1. **Lag Detected**: signal_delta=1.5 (>1.0), price_delta=0.01 (<0.02) → lag_flag=true
2. **No Lag (Signal Low)**: signal_delta=0.5 (<1.0) → lag_flag=false
3. **No Lag (Price Reacted)**: signal_delta=1.5 (>1.0), price_delta=0.05 (>0.02) → lag_flag=false

### Implementation

```java
@Test
public void testLagDetection() throws Exception {
    StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment();
    env.setParallelism(1);

    // Test case 1: Lag detected
    DataStream<Joined> joined1 = env.fromElements(
        new Joined("market1", 1.5, 0.01)  // signal_delta=1.5, price_delta=0.01
    );

    DataStream<LagSignal> lagSignals1 = joined1.map(record -> {
        double signalDelta = record.getSignalDelta();
        double priceDelta = record.getPriceDelta();
        boolean lagFlag = signalDelta > 1.0 && Math.abs(priceDelta) < 0.02;
        return new LagSignal(record.getMarket(), lagFlag);
    });

    List<LagSignal> results1 = collectResults(lagSignals1);
    assertEquals(1, results1.size());
    assertTrue("Lag should be detected", results1.get(0).isLagFlag());

    // Test case 2: No lag (signal low)
    DataStream<Joined> joined2 = env.fromElements(
        new Joined("market1", 0.5, 0.01)  // signal_delta=0.5, price_delta=0.01
    );

    DataStream<LagSignal> lagSignals2 = joined2.map(record -> {
        double signalDelta = record.getSignalDelta();
        double priceDelta = record.getPriceDelta();
        boolean lagFlag = signalDelta > 1.0 && Math.abs(priceDelta) < 0.02;
        return new LagSignal(record.getMarket(), lagFlag);
    });

    List<LagSignal> results2 = collectResults(lagSignals2);
    assertEquals(1, results2.size());
    assertFalse("Lag should not be detected", results2.get(0).isLagFlag());
}
```

**MarketLag**: Tests lag detection logic with various scenarios.

---

## Minimum Viable Code

```java
public class MarketLagTestingDemo {
    @Test
    public void testJob1WindowAggregation() {
        // Test Job 1: Window aggregation
        // Verify mention_count, keyword_score, source_weighted_signal
    }

    @Test
    public void testJob3Join() {
        // Test Job 3: Equi-join
        // Verify window_start = event_time matching
    }

    @Test
    public void testStateRecovery() {
        // Test state recovery
        // Verify max_signal_delta state restoration
    }

    @Test
    public void testWatermarkBehavior() {
        // Test watermark behavior
        // Verify late data handling, window triggering
    }

    @Test
    public void testLagDetection() {
        // Test lag detection logic
        // Verify signal_delta > 1.0 AND abs(price_delta) < 0.02
    }
}
```

---

## Common Mistakes

1. **Not testing edge cases**:
   - ❌ Only testing happy path
   - ✅ Test edge cases (missing data, boundary values)

2. **Not verifying calculations**:
   - ❌ Only checking output exists
   - ✅ Verify exact values (mention_count, signals, etc.)

3. **Not testing state**:
   - ❌ Only testing output, not state
   - ✅ Verify state values (max_signal_delta)

4. **Not testing late data**:
   - ❌ Only testing on-time data
   - ✅ Test late data handling

5. **Not testing join alignment**:
   - ❌ Assuming joins work correctly
   - ✅ Verify window_start = event_time matching

---

## Mind Trigger: When to Think About This

Think about project-specific testing when:
- **Testing MarketLag logic**: Test Job 1, Job 3, lag detection
- **Validating calculations**: Verify signal calculations, confidence scores
- **State verification**: Verify state (max_signal_delta) is correct
- **Business logic**: Test lag detection algorithm correctness
- **Before deployment**: Validate all project-specific logic

**In MarketLag project**: Tests window aggregation (Job 1), join correctness (Job 3), state recovery, watermark behavior, and lag detection logic. Understanding project-specific testing is essential for validating business logic.

---

## Summary

Project-specific testing scenarios validate MarketLag's unique functionality. Test window aggregation (Job 1), join correctness (Job 3), state recovery, watermark behavior, and lag detection logic. Use local and integration testing. MarketLag tests all project-specific scenarios before deployment. Understanding project-specific testing is essential for validating business logic.

